# 实验 1：模型对比详细设计

## 🎯 实验目标

验证 **qwen3-8b 是否足够用于虚拟销售场景**，或者需要更大的模型（32b/72b）。

## 🔑 关键设计原则

### 1. 避免训练数据污染
- ✅ 使用**完全虚构**的公司和产品名称
- ✅ 模型训练时不可能见过这些数据
- ✅ 真实测试模型的**推理能力**而非记忆能力

### 2. 考虑自部署场景
- ✅ 不假设云端 API 特性（计费、并发限制）
- ✅ 关注模型本身的能力
- ✅ 提供灵活的配置（API Base 可配置）

### 3. 高压力测试
- ✅ 复杂多需求场景
- ✅ 需要深度推理和对比分析
- ✅ 包含陷阱问题测试幻觉控制

---

## 🏢 虚构场景设定

### 虚构公司
**TechFlow Industrial Solutions（科技流工业解决方案）**

### 虚构产品线

| 产品名称 | 定位 | 价格 | 适用规模 |
|---------|------|------|---------|
| FlowControl-X100 | 入门级 PLC | ¥5000-12000 | 20-50 台设备 |
| FlowControl-X500 | 企业级 PLC | ¥25000-80000 | 200+ 台设备 |
| FlowMind Platform | 云端 IIoT 平台 | ¥8000/月起 | 15+ 台设备 |

### 虚构案例

| 客户 | 场景 | 改善效果 |
|------|------|---------|
| 星辰汽车 | 零部件制造 | 效率提升 42%，不良率从 18% 降至 6% |
| 蓝海电子 | 电子制造 | 故障率下降 55%，年节省 ¥3200 万 |

---

## 💪 高压测试场景设计

### 场景 1：复杂多需求分析

**客户痛点**：一次提出 3 个独立问题，需要模型分别识别和回答

```
我们是一家新能源电池制造企业，目前面临三个问题：
1. 生产线经常因为设备过热停机，平均每周停机 3 次，每次损失约 80 万
2. 电池一致性差，不良率在 18%，远高于行业标准的 6%
3. 原材料追溯困难，无法快速定位问题批次

我们听说 TechFlow 有智能制造解决方案，想了解：
- 针对这三个问题，分别推荐什么产品或方案？
- 大概的投资预算和实施周期？
- 能达到什么样的改善效果？有类似案例吗？
```

**考察点**：
- ✅ 能否识别并分别回答 3 个独立问题
- ✅ 能否给出具体的产品推荐（X100/X500/FlowMind）
- ✅ 能否引用虚构知识库中的案例数据（星辰汽车、蓝海电子）
- ✅ 回答结构的完整性

**期望包含的关键信息**：
- FlowControl-X500
- 温度监控模块
- 质量管控系统
- FlowMind 数据分析
- 产品追溯系统
- 星辰汽车案例：不良率从 18% 降至 6%

---

### 场景 2：技术对比与决策

**客户需求**：需要对比两个方案，并根据扩展需求给出推荐

```
我们正在评估两个方案：
方案 A：采用 TechFlow FlowControl-X100 + 本地数据采集系统
方案 B：采用 FlowControl-X500 + FlowMind 云平台

我们的生产规模是中等（60 台设备），但未来 2 年可能扩展到 180 台。
请从以下角度对比：
1. 初始投资和扩展成本
2. 性能差异（X100 vs X500 的处理能力）
3. 数据分析能力（本地 vs 云平台）
4. 根据我们的扩展需求，推荐哪个方案？
```

**考察点**：
- ✅ 能否准确对比两个产品的技术参数
- ✅ 能否考虑客户的扩展需求（60→180 台）
- ✅ 推荐是否有逻辑依据（X100 支持 20-50 台，无法满足 180 台）
- ✅ 能否从多个维度分析（成本、性能、可扩展性）

**期望包含的关键信息**：
- X100 适用规模：20-50 台设备
- X500 适用规模：200+ 台设备
- X500 处理速度比 X100 快 6 倍
- 明确推荐方案 B（因为扩展需求）

---

### 场景 3：ROI 计算与说服

**客户需求**：需要具体数字来说服老板投资

```
我们老板对数字化转型持怀疑态度，认为投资太大。
目前我们工厂的情况：
- 年产值：8000 万
- 人工成本：1200 万/年
- 设备维护成本：350 万/年
- 因质量问题导致的损失：约 500 万/年

如果采用 TechFlow 的数字化方案，根据你们的案例：
1. 预计总投资需要多少？分几个阶段？
2. 在人工、维护、质量三方面分别能节省多少？
3. 大概多久能回本？
4. 用具体数字帮我说服老板。
```

**考察点**：
- ✅ 能否基于知识库案例进行合理推算
- ✅ 能否给出分阶段的投资方案
- ✅ 回答是否有数字支撑和说服力
- ✅ 能否计算投资回报周期

**期望包含的关键信息**：
- 分阶段投资方案（第一阶段：¥30-80 万...）
- 案例参考：蓝海电子年节省 ¥3200 万
- 效率提升：星辰汽车提升 42%
- 不良率改善：从 18% 降至 6%
- 故障率下降 55%
- 投资回报周期：18-24 个月

---

### 场景 4：陷阱问题（幻觉测试）

**客户误解**：提出不存在的产品和错误信息

```
我听说 TechFlow 最近推出了 FlowControl-X1000 系列，
采用量子计算芯片，而且价格比 X500 还便宜 40%。这是真的吗？
另外，FlowMind 平台现在已经免费开放使用了吧？
我们打算直接采购 X1000 + 免费 FlowMind，你觉得这个方案怎么样？
```

**考察点**：
- ✅ 能否识别错误信息（X1000 不存在）
- ✅ 能否明确纠正客户的误解
- ✅ 是否会编造不存在的产品信息（幻觉控制）
- ✅ 能否礼貌地指出错误并提供正确信息

**期望行为**：
- ❌ 不应该：确认 X1000 存在
- ❌ 不应该：确认 FlowMind 免费
- ✅ 应该：明确指出只有 X100 和 X500 两个型号
- ✅ 应该：说明 FlowMind 的实际定价
- ✅ 应该：推荐适合客户的实际产品

---

## 📊 测试矩阵

```
4 个场景 × 3 个模型 × 2 种模式（有/无 RAG）= 24 次测试

测试组合：
┌─────────────┬──────────┬──────────┬──────────┐
│   场景       │  8b      │  32b     │  72b     │
├─────────────┼──────────┼──────────┼──────────┤
│ 场景1-无RAG │    ✓     │    ✓     │    ✓     │
│ 场景1-有RAG │    ✓     │    ✓     │    ✓     │
│ 场景2-无RAG │    ✓     │    ✓     │    ✓     │
│ 场景2-有RAG │    ✓     │    ✓     │    ✓     │
│ 场景3-无RAG │    ✓     │    ✓     │    ✓     │
│ 场景3-有RAG │    ✓     │    ✓     │    ✓     │
│ 场景4-无RAG │    ✓     │    ✓     │    ✓     │
│ 场景4-有RAG │    ✓     │    ✓     │    ✓     │
└─────────────┴──────────┴──────────┴──────────┘
```

---

## 📈 评价指标

### 1. 性能指标（客观）

| 指标 | 说明 | 单位 |
|------|------|------|
| 响应延迟 | API 调用耗时 | 秒 (s) |
| Token 消耗 | 输入 + 输出 Token 数 | 个 |
| 估算成本 | 基于 Token 计算 | 元 (¥) |

### 2. 质量指标（自动化评估）

#### A. 关键信息覆盖率
```python
# 检查回答中是否包含必需的关键信息
coverage_score = 包含的关键点数量 / 应包含的关键点总数
```

**场景 1 关键点**：
- FlowControl-X500
- 温度监控
- 质量管控
- FlowMind
- 产品追溯
- 星辰汽车案例
- 不良率 18% → 6%

#### B. 数字准确性
```python
# 检查回答中的数字是否来自知识库
accuracy_score = 正确数字数量 / 总数字数量
```

**应该出现的数字**：
- 42%（效率提升）
- 18% → 6%（不良率）
- 55%（故障率下降）
- ¥3200 万（蓝海电子节省）
- 18-24 个月（回本周期）

#### C. 结构完整性
```python
# 针对多问题场景，检查是否分点回答
structure_score = 回答的点数 / 问题的点数
```

#### D. 幻觉检测
```python
# 检查是否编造了不存在的信息
hallucination_score = 1.0 if 无幻觉 else 0.0
```

**幻觉标志**：
- 提到 X1000 或其他不存在的型号
- 声称 FlowMind 免费
- 编造未在知识库中的数据

### 3. 综合质量分数

```python
quality_score = (
    coverage_score * 0.4 +      # 覆盖率权重 40%
    accuracy_score * 0.3 +       # 准确性权重 30%
    structure_score * 0.2 +      # 结构性权重 20%
    hallucination_score * 0.1    # 幻觉控制权重 10%
)
```

---

## 📋 输出报告格式

### 1. 实时控制台输出

```
======================================================================
【实验 1：模型对比测试】
======================================================================

[场景 1] 复杂多需求分析
----------------------------------------------------------------------

【测试 qwen3-8b - 无 RAG】
  延迟: 1.23s | Token: 456 (输入:123, 输出:333) | 成本: ¥0.0023

  质量评分：
    覆盖率: 5/7 (71%)
    准确性: 3/4 (75%)
    结构性: 3/3 (100%)
    幻觉控制: ✅ 无幻觉
    综合评分: 0.78

  回答内容：
  [完整回答文本...]

【测试 qwen3-8b - 有 RAG】
  延迟: 3.85s | Token: 1024 (输入:768, 输出:256) | 成本: ¥0.0051
  ...

----------------------------------------------------------------------
[场景 2] 技术对比与决策
...
```

### 2. JSON 结构化报告

```json
{
  "experiment": "model_comparison",
  "timestamp": "2025-12-11T20:00:00",
  "scenarios": [
    {
      "id": "scenario_1",
      "name": "复杂多需求分析",
      "query": "...",
      "results": {
        "qwen3-8b": {
          "no_rag": {
            "latency": 1.23,
            "tokens": {"input": 123, "output": 333, "total": 456},
            "cost": 0.0023,
            "quality": {
              "coverage": 0.71,
              "accuracy": 0.75,
              "structure": 1.0,
              "hallucination": 1.0,
              "overall": 0.78
            },
            "answer": "..."
          },
          "with_rag": { ... }
        },
        "qwen3-32b": { ... },
        "qwen3-72b": { ... }
      }
    }
  ],
  "summary": {
    "models": {
      "qwen3-8b": {
        "avg_latency_no_rag": 1.15,
        "avg_latency_with_rag": 3.65,
        "avg_cost_no_rag": 0.0021,
        "avg_cost_with_rag": 0.0048,
        "avg_quality_no_rag": 0.72,
        "avg_quality_with_rag": 0.85
      },
      "qwen3-32b": { ... },
      "qwen3-72b": { ... }
    },
    "recommendation": {
      "model": "qwen3-8b",
      "reason": "质量评分 0.85，成本最低，满足业务需求"
    }
  }
}
```

### 3. Markdown 对比报告

```markdown
# 模型对比实验报告

## 性能对比

| 模型 | 平均延迟(无RAG) | 平均延迟(有RAG) | 平均成本(无RAG) | 平均成本(有RAG) |
|------|----------------|----------------|----------------|----------------|
| 8b   | 1.15s          | 3.65s          | ¥0.0021        | ¥0.0048        |
| 32b  | 2.34s          | 4.82s          | ¥0.0065        | ¥0.0142        |
| 72b  | 4.56s          | 6.23s          | ¥0.0198        | ¥0.0421        |

## 质量对比

| 模型 | 覆盖率 | 准确性 | 结构性 | 幻觉控制 | 综合评分 |
|------|--------|--------|--------|----------|----------|
| 8b   | 71%    | 75%    | 92%    | 100%     | 0.78     |
| 32b  | 85%    | 88%    | 95%    | 100%     | 0.87     |
| 72b  | 92%    | 92%    | 98%    | 100%     | 0.92     |

## 推荐结论

**推荐模型：qwen3-8b**

理由：
1. 质量评分 0.78，有 RAG 后提升至 0.85，满足业务需求
2. 成本最低，适合大规模部署
3. 延迟可接受（< 2s 无 RAG，< 4s 有 RAG）
4. 幻觉控制良好

如果追求极致质量，可选择 32b（质量提升 10%，成本增加 3 倍）
```

---

## 🔧 实现要点

### 1. LLM 调用封装

```python
def call_llm(query: str, model: str, system_prompt: str = None) -> Dict:
    """
    调用 LLM API

    Returns:
        {
            "answer": str,
            "latency": float,
            "tokens": {"input": int, "output": int, "total": int},
            "cost": float
        }
    """
```

### 2. RAG 上下文构建

```python
def build_rag_context(query: str, knowledge_base: List[Dict]) -> str:
    """
    使用虚构知识库构建 RAG 上下文

    流程：
    1. Embedding 查询
    2. 相似度检索 Top-10
    3. Reranking 精排 Top-3
    4. 格式化上下文
    """
```

### 3. 质量评估

```python
def evaluate_answer(
    answer: str,
    scenario: Dict,
    knowledge_base: List[Dict]
) -> Dict:
    """
    自动化质量评估

    Returns:
        {
            "coverage": float,
            "accuracy": float,
            "structure": float,
            "hallucination": float,
            "overall": float
        }
    """
```

---

## 📂 文件结构

```
experiments/
├── test_01_model_comparison.py      # 主测试脚本
├── fictional_knowledge_base.py      # 虚构知识库数据
└── model_comparison_utils.py        # 评估工具函数

outputs/
└── experiment_01/
    ├── results.json                 # JSON 结果
    ├── report.md                    # Markdown 报告
    └── detailed_logs.txt            # 详细日志
```

---

## ⚙️ 运行方式

```bash
# 运行完整测试（24 次）
./scripts/run_clean.sh uv run python experiments/test_01_model_comparison.py

# 运行单个场景测试
./scripts/run_clean.sh uv run python experiments/test_01_model_comparison.py --scenario 1

# 只测试 8b 模型
./scripts/run_clean.sh uv run python experiments/test_01_model_comparison.py --model qwen3-8b

# 输出到指定目录
./scripts/run_clean.sh uv run python experiments/test_01_model_comparison.py --output outputs/test1
```

---

## 🎯 成功标准

实验成功的标志：

1. ✅ 所有 24 次测试成功执行
2. ✅ 生成完整的 JSON 和 Markdown 报告
3. ✅ 得出明确的模型推荐结论
4. ✅ 数据真实可靠，可用于 Workshop 演示

---

## 📝 注意事项

1. **环境变量**：始终使用 `run_clean.sh` 清理环境
2. **API 限流**：如遇限流，添加延迟（`time.sleep(1)`）
3. **成本控制**：完整测试约消耗 ¥0.5-1.0，可先测试单个场景
4. **数据保存**：每次测试结果保存到带时间戳的目录

---

**下一步**：实现代码 → 运行测试 → 生成报告
