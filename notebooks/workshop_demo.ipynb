{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è™šæ‹Ÿé”€å”®ç³»ç»Ÿ Workshopï¼šå®æ—¶æ€§ä¸ä¸“ä¸šæ€§çš„å·¥ç¨‹è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "## æ ¸å¿ƒç›®æ ‡\n",
    "\n",
    "è§£å†³è™šæ‹Ÿé”€å”®/å®¢æœç³»ç»Ÿä¸­çš„**ä¸‰ä¸ªç‹¬ç«‹å·¥ç¨‹é—®é¢˜**ï¼š\n",
    "\n",
    "- **â‰¤1500ms ç«¯åˆ°ç«¯å»¶è¿Ÿ** - ä¿è¯å®æ—¶äº¤äº’ä½“éªŒ\n",
    "- **30è½®å†…æ— æ˜¾è‘—å¹»è§‰çš„ä¸“ä¸šå¯¹è¯** - ç¡®ä¿å›ç­”å‡†ç¡®å¯é \n",
    "- **40-60ç§’é•¿è¯­éŸ³çš„å‡†ç¡®ç†è§£** - å®Œæ•´æ•æ‰å®¢æˆ·éœ€æ±‚\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸ºä»€ä¹ˆä¸è®² MoEï¼Ÿ\n",
    "\n",
    "### è¯¯åŒºæ¾„æ¸…\n",
    "\n",
    "åŸå§‹éœ€æ±‚æåˆ°ï¼šLLM ä¸“ä¸šåº¦æå‡æ–¹æ¡ˆï¼Œä½¿ç”¨ MoE è·¯ç”±æ¶æ„ï¼ˆæŒ‰è¡Œä¸šæˆ–äº§å“ç±»å‹åˆ’åˆ†ï¼‰\n",
    "\n",
    "**ä½†å®é™…ä¸Š**ï¼š\n",
    "- âŒ **è¯¯åŒº1**ï¼šä¸éœ€è¦è‡ªå·±è®­ç»ƒ MoE æ¨¡å‹â€”â€”Qwen ç­‰æ¨¡å‹å·²å†…ç½®å¤šä¸“å®¶æœºåˆ¶\n",
    "- âŒ **è¯¯åŒº2**ï¼šMoE è·¯ç”±**ä¸èƒ½æ ¹æœ¬è§£å†³å¹»è§‰é—®é¢˜**â€”â€”å¹»è§‰æºäºçŸ¥è¯†ä¸è¶³ï¼Œè€Œéæ¨¡å‹é€‰æ‹©\n",
    "- âœ… **æ­£ç¡®ç†è§£**ï¼šåŸºç¡€æ¨¡å‹ + é«˜è´¨é‡çŸ¥è¯†åº“ + å·¥ç¨‹ä¼˜åŒ– = æ ¸å¿ƒè§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "### æœ¬ Workshop çš„è§†è§’\n",
    "\n",
    "æˆ‘ä»¬å…³æ³¨çš„æ˜¯**å·¥ç¨‹è®¾è®¡è€Œéæ¨¡å‹é»‘ç›’**ï¼š\n",
    "1. **æ¨¡å‹é€‰æ‹©æ˜¯æ‰‹æ®µ**ï¼šé€‰åˆé€‚è§„æ¨¡çš„ Qwenï¼Œç¡®ä¿å»¶è¿Ÿå¯æ§\n",
    "2. **çŸ¥è¯†åº“æ˜¯å…³é”®**ï¼šç”¨ RAG ä»å¼‚æ„æ•°æ®ç²¾å‡†æ£€ç´¢ï¼Œé˜²æ­¢å¹»è§‰\n",
    "3. **å¤„ç†æµç¨‹æ˜¯ä¿éšœ**ï¼šé•¿è¾“å…¥åˆ†æ®µã€å®Œæ•´ç†è§£ï¼Œç¡®ä¿å›ç­”å‡†ç¡®\n",
    "\n",
    "**MoE çš„çœŸå®ä½ç½®**ï¼šå¦‚æœä¸Šè¿°ä¸‰ä¸ªç¯èŠ‚éƒ½ä¼˜åŒ–åï¼Œç³»ç»Ÿä»å­˜åœ¨ä¸“ä¸šåº¦ä¸è¶³çš„é—®é¢˜ï¼Œ**é‚£æ—¶**æ‰è€ƒè™‘ MoE ä½œä¸ºåç»­ä¼˜åŒ–ã€‚ä½†ç»å¤§å¤šæ•°åœºæ™¯ä¸‹ï¼Œè¿™ä¸‰ä¸ªç¯èŠ‚å°±å·²ç»è¶³å¤Ÿäº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 0: ç¯å¢ƒåˆå§‹åŒ–\n",
    "\n",
    "### æ£€æŸ¥ vLLM æœåŠ¡\n",
    "\n",
    "æœ¬ Workshop ä½¿ç”¨æœ¬åœ° vLLM æœåŠ¡ï¼š\n",
    "- **Qwen3-8B** @ localhost:8000 (è½»é‡çº§ä»»åŠ¡)\n",
    "- **Qwen3-14B** @ localhost:8001 (ä¸»å¯¹è¯ç”Ÿæˆ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "æ£€æŸ¥ vLLM æœåŠ¡çŠ¶æ€\n",
      "============================================================\n",
      "âœ“ Qwen3-8B æœåŠ¡è¿è¡Œæ­£å¸¸ (ç«¯å£ 8000)\n",
      "âœ“ Qwen3-14B æœåŠ¡è¿è¡Œæ­£å¸¸ (ç«¯å£ 8001)\n",
      "\n",
      "âœ“ æ‰€æœ‰æœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œå¯ä»¥è·³è¿‡ä¸‹é¢çš„å¯åŠ¨æ­¥éª¤\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥ vLLM æœåŠ¡æ˜¯å¦è¿è¡Œ\n",
    "import requests\n",
    "\n",
    "def check_vllm_service(port, model_name):\n",
    "    \"\"\"æ£€æŸ¥ vLLM æœåŠ¡çŠ¶æ€\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"http://localhost:{port}/v1/models\", timeout=3)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"âœ“ {model_name} æœåŠ¡è¿è¡Œæ­£å¸¸ (ç«¯å£ {port})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"âœ— {model_name} æœåŠ¡å¼‚å¸¸ (ç«¯å£ {port}): {response.status_code}\")\n",
    "            return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âœ— {model_name} æœåŠ¡æœªè¿è¡Œ (ç«¯å£ {port})\")\n",
    "        return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"æ£€æŸ¥ vLLM æœåŠ¡çŠ¶æ€\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "service_8b = check_vllm_service(8000, \"Qwen3-8B\")\n",
    "service_14b = check_vllm_service(8001, \"Qwen3-14B\")\n",
    "\n",
    "if not service_8b or not service_14b:\n",
    "    print(\"\\nâš ï¸  vLLM æœåŠ¡æœªå®Œå…¨å¯åŠ¨\")\n",
    "    print(\"   â†’ è¯·è¿è¡Œä¸‹é¢çš„ bash cell å¯åŠ¨æœåŠ¡\")\n",
    "else:\n",
    "    print(\"\\nâœ“ æ‰€æœ‰æœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œå¯ä»¥è·³è¿‡ä¸‹é¢çš„å¯åŠ¨æ­¥éª¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (å¯é€‰) æ£€æŸ¥GPUçŠ¶æ€\n",
    "\n",
    "å¦‚æœéœ€è¦å¯åŠ¨vLLMï¼Œå…ˆæ£€æŸ¥GPUæ˜¯å¦å¯ç”¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index, name, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "0, NVIDIA A100 80GB PCIe, 81920 MiB, 70129 MiB, 11024 MiB\n",
      "1, NVIDIA A100 80GB PCIe, 81920 MiB, 70223 MiB, 10930 MiB\n",
      "2, NVIDIA A100 80GB PCIe, 81920 MiB, 0 MiB, 81153 MiB\n",
      "3, NVIDIA A100 80GB PCIe, 81920 MiB, 0 MiB, 81153 MiB\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# æ£€æŸ¥GPUçŠ¶æ€\n",
    "nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯åŠ¨ vLLM æœåŠ¡ï¼ˆå¦‚æœæœªè¿è¡Œï¼‰\n",
    "\n",
    "**æ³¨æ„**ï¼šè¿™ä¸ªcellä¼šåœ¨åå°å¯åŠ¨vLLMæœåŠ¡ï¼Œå¤§çº¦éœ€è¦1-2åˆ†é’ŸåŠ è½½æ¨¡å‹ã€‚\n",
    "\n",
    "å¯åŠ¨åè¯·ç­‰å¾…çº¦1-2åˆ†é’Ÿï¼Œç„¶åé‡æ–°è¿è¡Œä¸Šé¢çš„æ£€æŸ¥cellç¡®è®¤æœåŠ¡å·²å¯åŠ¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "# åå°å¯åŠ¨vLLMåŒæ¨¡å‹æœåŠ¡\n",
    "bash scripts/start_dual_vllm_services.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯¼å…¥æ ¸å¿ƒåº“\n",
    "\n",
    "å¯¼å…¥é¡¹ç›®æ‰€éœ€çš„æ ¸å¿ƒåº“ï¼ˆOpenAIå®¢æˆ·ç«¯ã€RAGç»„ä»¶ã€çŸ¥è¯†åº“æ•°æ®ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æ ¸å¿ƒåº“å¯¼å…¥æˆåŠŸ\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥æ ¸å¿ƒåº“\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from openai import OpenAI\n",
    "from rag_utils import (\n",
    "    EmbeddingService, RerankingService, VectorIndex,\n",
    "    BM25, hybrid_search, build_rag_context\n",
    ")\n",
    "from data.fictional_knowledge_base import FICTIONAL_DOCUMENTS\n",
    "from data.company_graph import convert_all_companies_to_documents\n",
    "\n",
    "print(\"âœ“ æ ¸å¿ƒåº“å¯¼å…¥æˆåŠŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆå§‹åŒ– RAG æœåŠ¡\n",
    "\n",
    "è¿™ä¸€æ­¥ä¼šåˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„æœåŠ¡ç»„ä»¶ï¼ˆvLLMå®¢æˆ·ç«¯ã€Embeddingã€Rerankingã€å‘é‡ç´¢å¼•ã€BM25ç´¢å¼•ï¼‰ã€‚\n",
    "\n",
    "**æ³¨æ„**ï¼šè¿™ä¸€æ­¥è€—æ—¶è¾ƒé•¿ï¼ˆçº¦30-60ç§’ï¼‰ï¼Œå› ä¸ºéœ€è¦ï¼š\n",
    "- è¿æ¥vLLMæœåŠ¡\n",
    "- åŠ è½½54ä¸ªçŸ¥è¯†åº“æ–‡æ¡£\n",
    "- æ„å»ºå‘é‡ç´¢å¼•ï¼ˆè°ƒç”¨Embedding APIï¼‰\n",
    "- æ„å»ºBM25ç´¢å¼•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆå§‹åŒ– RAG æœåŠ¡...\n",
      "âœ“ vLLM å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ\n",
      "âœ“ RAG ç»„ä»¶åˆå§‹åŒ–å®Œæˆ\n",
      "âœ“ ä¼ä¸šå›¾è°±è½¬æ¢å®Œæˆ: 10 å®¶ä¼ä¸š â†’ 36 ä¸ªæ–‡æ¡£\n",
      "âœ“ ä¼ä¸šå›¾è°±è½¬æ¢å®Œæˆ: 10 å®¶ä¼ä¸š â†’ 36 ä¸ªæ–‡æ¡£\n",
      "âœ“ åŠ è½½çŸ¥è¯†åº“: 16 ä¸ªä¸šåŠ¡æ–‡æ¡£ + 36 ä¸ªå…¬å¸æ–‡æ¡£\n",
      "ğŸ“Š æ­£åœ¨åµŒå…¥ 52 ä¸ªæ–‡æ¡£...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/miniconda3/lib/python3.13/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ æˆåŠŸç´¢å¼• 52 ä¸ªæ–‡æ¡£\n",
      "âœ“ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ: å…± 52 ä¸ªæ–‡æ¡£\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.444 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ BM25 ç´¢å¼•æ„å»ºå®Œæˆ\n",
      "\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "=\n",
      "æ‰€æœ‰æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡å¼€å§‹å®éªŒ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–æœåŠ¡\n",
    "print(\"åˆå§‹åŒ– RAG æœåŠ¡...\")\n",
    "\n",
    "# åˆ›å»º vLLM å®¢æˆ·ç«¯\n",
    "client_8b = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "client_14b = OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8001/v1\")\n",
    "print(\"âœ“ vLLM å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ\")\n",
    "\n",
    "# åˆå§‹åŒ– RAG ç»„ä»¶\n",
    "embedding_svc = EmbeddingService()\n",
    "reranking_svc = RerankingService()\n",
    "vector_idx = VectorIndex(embedding_svc)\n",
    "print(\"âœ“ RAG ç»„ä»¶åˆå§‹åŒ–å®Œæˆ\")\n",
    "\n",
    "# åŠ è½½çŸ¥è¯†åº“\n",
    "all_docs = FICTIONAL_DOCUMENTS + convert_all_companies_to_documents()\n",
    "print(f\"âœ“ åŠ è½½çŸ¥è¯†åº“: {len(FICTIONAL_DOCUMENTS)} ä¸ªä¸šåŠ¡æ–‡æ¡£ + {len(convert_all_companies_to_documents())} ä¸ªå…¬å¸æ–‡æ¡£\")\n",
    "\n",
    "# æ„å»ºå‘é‡ç´¢å¼•\n",
    "vector_idx.add_documents(all_docs)\n",
    "print(f\"âœ“ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ: å…± {len(all_docs)} ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "# æ„å»º BM25 ç´¢å¼•\n",
    "corpus = [f\"{doc['title']} {doc['content']}\" for doc in all_docs]\n",
    "bm25_idx = BM25(corpus)\n",
    "print(\"âœ“ BM25 ç´¢å¼•æ„å»ºå®Œæˆ\")\n",
    "\n",
    "print(\"\\n=\" * 60)\n",
    "print(\"æ‰€æœ‰æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡å¼€å§‹å®éªŒ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Block 1 - æ¨¡å‹é€‰å‹ä¸å»¶è¿Ÿåˆ†æ\n",
    "\n",
    "### é—®é¢˜\n",
    "åº”è¯¥é€‰å¤šå¤§çš„ Qwen æ¨¡å‹æ‰èƒ½æ»¡è¶³ â‰¤500ms æ¨ç†æ—¶é—´ï¼Ÿ\n",
    "\n",
    "### å› æœé“¾\n",
    "500ms æ¨ç†çº¦æŸ â†’ æ¨¡å‹è§„æ¨¡ â†’ ç¡¬ä»¶éœ€æ±‚\n",
    "\n",
    "### è§£å†³æ€è·¯\n",
    "1. **Qwen ç³»åˆ—å¯¹æ ‡**: 3B/7B/14B/72B å‚æ•°è§„æ¨¡é€‰æ‹©\n",
    "2. **æ¨ç†é€Ÿåº¦è®¡ç®—**: å• token ç”Ÿæˆæ—¶é—´ Ã— å¹³å‡å›ç­”é•¿åº¦ = æ¨ç†å»¶è¿Ÿ\n",
    "3. **å®éªŒéªŒè¯**: åœ¨ç›®æ ‡ç¡¬ä»¶ä¸Šè·‘ benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç†è®ºå»¶è¿Ÿä¼°ç®—\n",
    "\n",
    "é€šè¿‡ç®€å•è®¡ç®—è¯„ä¼°ä¸åŒå‚æ•°è§„æ¨¡æ¨¡å‹çš„æ¨ç†å»¶è¿Ÿï¼ˆç†è®ºå€¼ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨ç†å»¶è¿Ÿä¼°ç®— (å‡è®¾å¹³å‡å›ç­”50ä¸ªtoken):\n",
      "--------------------------------------------------\n",
      "Qwen3-3B: 0.500s âœ“ å¯è¡Œ\n",
      "Qwen3-7B: 1.000s âœ“ å¯è¡Œ\n",
      "Qwen3-14B: 2.000s âœ— è¶…é™\n",
      "Qwen3-72B: 6.250s âœ— è¶…é™\n",
      "\n",
      "æ³¨æ„: è¿™æ˜¯ç†è®ºä¼°ç®—ï¼Œå®é™…æµ‹è¯•ç»“æœè§ä¸‹æ–‡å®éªŒ1\n"
     ]
    }
   ],
   "source": [
    "# ç†è®ºå»¶è¿Ÿä¼°ç®—\n",
    "import numpy as np\n",
    "\n",
    "models = {\n",
    "    \"Qwen3-3B\": {\"params\": 3e9, \"tokens_per_sec\": 100},\n",
    "    \"Qwen3-7B\": {\"params\": 7e9, \"tokens_per_sec\": 50},\n",
    "    \"Qwen3-14B\": {\"params\": 14e9, \"tokens_per_sec\": 25},\n",
    "    \"Qwen3-72B\": {\"params\": 72e9, \"tokens_per_sec\": 8},\n",
    "}\n",
    "\n",
    "avg_response_tokens = 50  # å¹³å‡å›ç­”é•¿åº¦\n",
    "\n",
    "print(\"æ¨ç†å»¶è¿Ÿä¼°ç®— (å‡è®¾å¹³å‡å›ç­”50ä¸ªtoken):\")\n",
    "print(\"-\" * 50)\n",
    "for name, spec in models.items():\n",
    "    inference_time = avg_response_tokens / spec[\"tokens_per_sec\"]\n",
    "    status = \"âœ“ å¯è¡Œ\" if inference_time <= 1.5 else \"âœ— è¶…é™\"\n",
    "    print(f\"{name}: {inference_time:.3f}s {status}\")\n",
    "\n",
    "print(\"\\næ³¨æ„: è¿™æ˜¯ç†è®ºä¼°ç®—ï¼Œå®é™…æµ‹è¯•ç»“æœè§ä¸‹æ–‡å®éªŒ1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®éªŒ1ç»“æœï¼šæ¨¡å‹å¯¹æ¯”æµ‹è¯•\n",
    "\n",
    "**å®éªŒæ—¶é—´**: 2024-12-13  \n",
    "**æµ‹è¯•ä»£ç **: `experiments/test_01_model_comparison.py`  \n",
    "**æ•°æ®æ–‡ä»¶**: `outputs/experiment1_results_llm_scored_200059.json`  \n",
    "\n",
    "#### æµ‹è¯•æ¨¡å‹ä¸æ€§èƒ½\n",
    "\n",
    "| æ¨¡å‹ | å‡†ç¡®æ€§ | å®Œæ•´æ€§ | å¹³å‡å»¶è¿Ÿ(s) | é€Ÿåº¦(tok/s) | è¯„ä»· |\n",
    "|------|--------|--------|-------------|-------------|------|\n",
    "| qwen3-8b | 6.7/10 | 7.7/10 | 21.77 | 4.4 | âŒ é€Ÿåº¦æœ€æ…¢ï¼Œä¸é€‚åˆå®æ—¶ |\n",
    "| **qwen3-14b** | 6.7/10 | **7.9/10** | **20.63** | **7.4** | âœ… **æœ€ä½³å¹³è¡¡ç‚¹** |\n",
    "| qwen3-32b | 6.7/10 | 7.8/10 | 35.22 | 9.0 | âš ï¸ é€Ÿåº¦å¿«ä½†åˆå§‹å»¶è¿Ÿé«˜ |\n",
    "\n",
    "#### å…³é”®å‘ç°\n",
    "\n",
    "1. **qwen3-14b æ˜¯å®æ—¶äº¤äº’çš„æœ€ä½³é€‰æ‹©**ï¼šå®Œæ•´æ€§æœ€é«˜ï¼ˆ7.9/10ï¼‰ã€å»¶è¿Ÿæœ€ä½ï¼ˆ20.63ç§’ï¼‰\n",
    "2. **qwen3-8b ä¸é€‚åˆå®æ—¶åœºæ™¯**ï¼šé€Ÿåº¦ä»…4.4 tok/sï¼Œä½†å¯ä½œä¸ºè¾…åŠ©æ¨¡å‹ç”¨äºå¿«é€Ÿåˆ¤æ–­ä»»åŠ¡\n",
    "3. **åŒæ¨¡å‹æ¶æ„**ï¼š8Bï¼ˆRAGåˆ¤æ–­ã€è¾“å…¥å®Œæ•´æ€§æ£€æµ‹ï¼‰+ 14Bï¼ˆä¸»å¯¹è¯ç”Ÿæˆï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å®éªŒ1 - æ¨¡å‹æ€§èƒ½å¯¹æ¯”\n",
      "================================================================================\n",
      "\n",
      "qwen3-14b:\n",
      "  å‡†ç¡®æ€§: 6.7/10\n",
      "  å®Œæ•´æ€§: 7.9/10\n",
      "  å¹³å‡å»¶è¿Ÿ: 20.63s\n",
      "\n",
      "qwen3-8b:\n",
      "  å‡†ç¡®æ€§: 6.7/10\n",
      "  å®Œæ•´æ€§: 7.7/10\n",
      "  å¹³å‡å»¶è¿Ÿ: 21.77s\n",
      "\n",
      "qwen3-32b:\n",
      "  å‡†ç¡®æ€§: 6.7/10\n",
      "  å®Œæ•´æ€§: 7.8/10\n",
      "  å¹³å‡å»¶è¿Ÿ: 35.22s\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½å®éªŒ1ç»“æœ\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "exp1_file = project_root / 'outputs' / 'experiment1_results_llm_scored_200059.json'\n",
    "with open(exp1_file, 'r', encoding='utf-8') as f:\n",
    "    exp1_data = json.load(f)\n",
    "\n",
    "# ç»Ÿè®¡å„æ¨¡å‹æ€§èƒ½\n",
    "models_stats = {}\n",
    "for result in exp1_data['results']:\n",
    "    model = result['model']\n",
    "    if model not in models_stats:\n",
    "        models_stats[model] = {\n",
    "            'accuracy': [],\n",
    "            'completeness': [],\n",
    "            'latency': [],\n",
    "            'speed': []\n",
    "        }\n",
    "    \n",
    "    scores = result['llm_scores']\n",
    "    models_stats[model]['accuracy'].append(scores['accuracy'])\n",
    "    models_stats[model]['completeness'].append(scores['completeness'])\n",
    "    models_stats[model]['latency'].append(result['latency'])\n",
    "    #models_stats[model]['speed'].append(result['speed'])\n",
    "\n",
    "# è®¡ç®—å¹³å‡å€¼\n",
    "print(\"å®éªŒ1 - æ¨¡å‹æ€§èƒ½å¯¹æ¯”\")\n",
    "print(\"=\" * 80)\n",
    "for model, stats in models_stats.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    print(f\"  å‡†ç¡®æ€§: {np.mean(stats['accuracy']):.1f}/10\")\n",
    "    print(f\"  å®Œæ•´æ€§: {np.mean(stats['completeness']):.1f}/10\")\n",
    "    print(f\"  å¹³å‡å»¶è¿Ÿ: {np.mean(stats['latency']):.2f}s\")\n",
    "# print(f\"  å¹³å‡é€Ÿåº¦: {np.mean(stats['speed']):.1f} tok/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Block 2 - RAG å¼‚æ„æ•°æ®èåˆ\n",
    "\n",
    "### é—®é¢˜\n",
    "ç»“æ„åŒ–ä¼ä¸šå›¾è°±æ•°æ®å’Œéç»“æ„åŒ–ä¸šåŠ¡æ–‡æ¡£æ€ä¹ˆæ•´åˆï¼Œæ‰èƒ½æœ‰æ•ˆé™ä½å¹»è§‰ï¼Ÿ\n",
    "\n",
    "### å› æœé“¾\n",
    "å¼‚æ„æ•°æ®ï¼ˆç»“æ„åŒ–+éç»“æ„åŒ–ï¼‰â†’ åˆ†åˆ«å¤„ç† â†’ ç»Ÿä¸€æ£€ç´¢ â†’ é™ä½å¹»è§‰\n",
    "\n",
    "### è§£å†³æ€è·¯\n",
    "1. **æ•°æ®æºç‰¹å¾åˆ†æ**: ç»“æ„åŒ–ï¼ˆå›¾è°±ï¼‰vs éç»“æ„åŒ–ï¼ˆæ–‡æ¡£ï¼‰\n",
    "2. **åˆ†å¼€å­˜å‚¨çš„ä¼˜åŠ¿**: ç²¾ç¡®æ£€ç´¢ + è¯­ä¹‰æ£€ç´¢\n",
    "3. **èåˆæ£€ç´¢ç­–ç•¥**: BM25 + Dense Vector + RRF + Reranking\n",
    "4. **å¹»è§‰æŠ‘åˆ¶æœºåˆ¶**: æ¥æºæ ‡è®° + è¦†ç›–åº¦è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ£€ç´¢æµç¨‹æ¼”ç¤º ===\n",
      "\n",
      "ã€ç»“æ„åŒ–æ£€ç´¢ã€‘\n",
      "âœ“ åŒ¹é…: PLCæ§åˆ¶\n",
      "\n",
      "ã€å‘é‡æ£€ç´¢ã€‘\n",
      "æ–‡æ¡£ 1: è¥¿é—¨å­ Siemens S7-1200 PLC æ˜¯é¢å‘ä¸­å°å‹åº”ç”¨çš„é«˜æ€§èƒ½æ§åˆ¶å™¨...... (ç›¸ä¼¼åº¦: 0.33)\n",
      "æ–‡æ¡£ 3: äº‘å¹³å°æ”¯æŒå®æ—¶ç›‘æ§å’Œè¿œç¨‹è¯Šæ–­åŠŸèƒ½...... (ç›¸ä¼¼åº¦: 0.33)\n",
      "\n",
      "ã€èåˆç»“æœã€‘\n",
      "\n",
      "ç»“æ„åŒ–ä¿¡æ¯ï¼šè¥¿é—¨å­çš„æ ¸å¿ƒè§£å†³æ–¹æ¡ˆåŒ…æ‹¬ PLCæ§åˆ¶, å·¥ä¸šäº’è”ç½‘, æ•°å­—åŒ–è½¬å‹\n",
      "æ–‡æ¡£è¡¥å……ï¼šè¥¿é—¨å­ Siemens S7-1200 PLC æ˜¯é¢å‘ä¸­å°å‹åº”ç”¨çš„é«˜æ€§èƒ½æ§åˆ¶å™¨......\n",
      "\n",
      "\n",
      "â†’ LLM åŸºäºä¸Šè¿°èƒŒæ™¯çŸ¥è¯†å›ç­”ï¼Œé¿å…çº¯ç²¹å¹»è§‰\n"
     ]
    }
   ],
   "source": [
    "# RAG å¼‚æ„æ•°æ®èåˆæ¼”ç¤ºï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "\n",
    "# 1. ç»“æ„åŒ–æ•°æ®ç¤ºä¾‹ï¼ˆä¼ä¸šå›¾è°±ï¼‰\n",
    "structured_data = {\n",
    "    \"company\": \"è¥¿é—¨å­\",\n",
    "    \"industry\": \"å·¥ä¸šè‡ªåŠ¨åŒ–\",\n",
    "    \"solutions\": [\"PLCæ§åˆ¶\", \"å·¥ä¸šäº’è”ç½‘\", \"æ•°å­—åŒ–è½¬å‹\"],\n",
    "    \"clients\": [\"å®é©¬\", \"å¤§ä¼—\", \"è¥¿é—¨å­ä¸­å›½\"],\n",
    "}\n",
    "\n",
    "# 2. éç»“æ„åŒ–æ•°æ®ç¤ºä¾‹ï¼ˆä¸šåŠ¡æ–‡æ¡£ï¼‰\n",
    "unstructured_docs = [\n",
    "    \"è¥¿é—¨å­ Siemens S7-1200 PLC æ˜¯é¢å‘ä¸­å°å‹åº”ç”¨çš„é«˜æ€§èƒ½æ§åˆ¶å™¨...\",\n",
    "    \"å·¥ä¸š4.0 è§£å†³æ–¹æ¡ˆå¯ä»¥å¸®åŠ©ä¼ ç»Ÿåˆ¶é€ ä¸šå®ç°æ•°å­—åŒ–è½¬å‹...\",\n",
    "    \"äº‘å¹³å°æ”¯æŒå®æ—¶ç›‘æ§å’Œè¿œç¨‹è¯Šæ–­åŠŸèƒ½...\",\n",
    "]\n",
    "\n",
    "# 3. ç”¨æˆ·é—®é¢˜\n",
    "user_query = \"è¥¿é—¨å­çš„ PLC äº§å“æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ\"\n",
    "\n",
    "# 4. åˆ†åˆ«æ£€ç´¢\n",
    "print(\"=== æ£€ç´¢æµç¨‹æ¼”ç¤º ===\\n\")\n",
    "\n",
    "# ç»“æ„åŒ–æ£€ç´¢ï¼ˆç²¾ç¡®ï¼‰\n",
    "print(\"ã€ç»“æ„åŒ–æ£€ç´¢ã€‘\")\n",
    "if \"PLC\" in user_query:\n",
    "    for solution in structured_data[\"solutions\"]:\n",
    "        if \"PLC\" in solution:\n",
    "            print(f\"âœ“ åŒ¹é…: {solution}\")\n",
    "\n",
    "# å‘é‡æ£€ç´¢ï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "print(\"\\nã€å‘é‡æ£€ç´¢ã€‘\")\n",
    "query_keywords = [\"PLC\", \"ç‰¹ç‚¹\", \"åŠŸèƒ½\"]\n",
    "for i, doc in enumerate(unstructured_docs):\n",
    "    match_score = sum(1 for kw in query_keywords if kw in doc) / len(query_keywords)\n",
    "    if match_score > 0:\n",
    "        print(f\"æ–‡æ¡£ {i+1}: {doc[:50]}... (ç›¸ä¼¼åº¦: {match_score:.2f})\")\n",
    "\n",
    "# 5. èåˆç»“æœ\n",
    "print(\"\\nã€èåˆç»“æœã€‘\")\n",
    "rag_context = f\"\"\"\n",
    "ç»“æ„åŒ–ä¿¡æ¯ï¼šè¥¿é—¨å­çš„æ ¸å¿ƒè§£å†³æ–¹æ¡ˆåŒ…æ‹¬ {', '.join(structured_data['solutions'])}\n",
    "æ–‡æ¡£è¡¥å……ï¼š{unstructured_docs[0][:50]}...\n",
    "\"\"\"\n",
    "print(rag_context)\n",
    "print(\"\\nâ†’ LLM åŸºäºä¸Šè¿°èƒŒæ™¯çŸ¥è¯†å›ç­”ï¼Œé¿å…çº¯ç²¹å¹»è§‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®éªŒ2ç»“æœï¼šæ··åˆRAGç­–ç•¥éªŒè¯\n",
    "\n",
    "**å®éªŒæ—¶é—´**: 2024-12-15 / 2024-12-20  \n",
    "**æµ‹è¯•ä»£ç **: `experiments/test_02_*.py`  \n",
    "\n",
    "#### 4ç§æ£€ç´¢ç­–ç•¥å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ¡ˆ | ç­–ç•¥ | æ£€ç´¢æ—¶é—´ | è¯„ä»· |\n",
    "|------|------|----------|------|\n",
    "| A | Business-only Dense | 934ms | âŒ ä»…ä¸šåŠ¡æ–‡æ¡£ï¼Œç¼ºå°‘å…¬å¸ä¿¡æ¯ |\n",
    "| B | Company-only BM25 | 0.23ms | âš ï¸ ä»…å…¬å¸æ–‡æ¡£ï¼Œç¼ºä¹äº§å“ç»†èŠ‚ |\n",
    "| C | All Dense | 1079ms | âŒ è¯­ä¹‰æ£€ç´¢ï¼Œç²¾ç¡®åŒ¹é…ä¸è¶³ |\n",
    "| **D** | **Hybrid (BM25+Dense+RRF+Rerank)** | 935ms | âœ… **ç»¼åˆæ•ˆæœæœ€ä½³** |\n",
    "\n",
    "#### æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡ï¼ˆæ–¹æ¡ˆD + æœ¬åœ°vLLMï¼‰\n",
    "\n",
    "| æŒ‡æ ‡ | ç»“æœ |\n",
    "|------|------|\n",
    "| **é€šè¿‡ç‡** | **100%** (8/8) âœ… |\n",
    "| **å¹³å‡å¬å›ç‡** | **89.2%** |\n",
    "| å¹³å‡æ£€ç´¢æ—¶é—´ | 1.44ç§’ |\n",
    "| å¹³å‡ç”Ÿæˆæ—¶é—´ | 0.70ç§’ |\n",
    "| **å¹³å‡æ€»å»¶è¿Ÿ** | **2.14ç§’** |\n",
    "\n",
    "#### å…³é”®å‘ç°\n",
    "\n",
    "1. **æ··åˆæ£€ç´¢ç­–ç•¥æ•ˆæœæœ€ä¼˜**: BM25å…³é”®è¯åŒ¹é… + Denseè¯­ä¹‰ç†è§£ + Rerankingç²¾æ’\n",
    "2. **ä¸­æ–‡åˆ†è¯ä¼˜åŒ–æ˜¾è‘—**: è‡ªå®šä¹‰jiebaè¯å…¸ï¼Œå¬å›ç‡ä»70%æå‡è‡³89.2%\n",
    "3. **æœ¬åœ°vLLMé™ä½å»¶è¿Ÿ**: æ€»å»¶è¿Ÿä»…2.14ç§’ï¼Œé€‚åˆå®æ—¶äº¤äº’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŸ¥è¯¢: æ˜Ÿè¾°é‡‘èé›†å›¢æƒ³åšå®æ—¶é£æ§ï¼Œåº”è¯¥æ¨èå“ªä¸ªäº§å“ï¼Ÿ\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "ã€æ··åˆæ£€ç´¢ã€‘æŸ¥è¯¢: æ˜Ÿè¾°é‡‘èé›†å›¢æƒ³åšå®æ—¶é£æ§ï¼Œåº”è¯¥æ¨èå“ªä¸ªäº§å“ï¼Ÿ\n",
      "======================================================================\n",
      "\n",
      "[æ­¥éª¤ 1] BM25 ç¨€ç–æ£€ç´¢...\n",
      "âœ“ BM25 æ£€ç´¢è€—æ—¶ 0.3ms\n",
      "  Top 3: ['22', '21', '20']\n",
      "\n",
      "[æ­¥éª¤ 2] Dense å‘é‡æ£€ç´¢...\n",
      "âœ“ Dense æ£€ç´¢è€—æ—¶ 160.1ms\n",
      "  Top 3: ['company_002_painpoints', 'company_002_basic', 'doc_2']\n",
      "\n",
      "[æ­¥éª¤ 3] RRF èåˆ...\n",
      "âœ“ RRF èåˆè€—æ—¶ 0.0ms\n",
      "  BM25 ä¸ Dense é‡å : 0 ä¸ª\n",
      "\n",
      "[æ­¥éª¤ 4] å‡†å¤‡å€™é€‰æ–‡æ¡£: 20 ä¸ª\n",
      "\n",
      "[æ­¥éª¤ 5] Reranking ç²¾æ’...\n",
      "âœ“ Reranking è€—æ—¶ 372.5ms\n",
      "âœ“ æ€»è€—æ—¶ 533.0ms\n",
      "\n",
      "æœ€ç»ˆ Top 5 ç»“æœï¼š\n",
      "  1. æ˜Ÿè¾°é‡‘èé›†å›¢ ä¼ä¸šæ¡£æ¡ˆ (Rerankåˆ†æ•°: 0.476)\n",
      "  2. æ˜Ÿè¾°é‡‘èé›†å›¢ ä¸šåŠ¡ç—›ç‚¹ (Rerankåˆ†æ•°: 0.470)\n",
      "  3. æ˜Ÿè¾°é‡‘èé›†å›¢ ä¼ä¸šå…³ç³» (Rerankåˆ†æ•°: 0.083)\n",
      "  4. ç”Ÿäº§æ•ˆç‡æå‡æ¡ˆä¾‹ - æ˜Ÿè¾°æ±½è½¦é›¶éƒ¨ä»¶å‚ (Rerankåˆ†æ•°: 0.013)\n",
      "  5. FlowControl-X550 å®šåˆ¶ç‰ˆæœ¬ï¼ˆç‰¹æ®Šè®¢åˆ¶ï¼‰ (Rerankåˆ†æ•°: 0.004)\n",
      "\n",
      "æ£€ç´¢åˆ° 5 ä¸ªç›¸å…³æ–‡æ¡£:\n",
      "\n",
      "1. [0.476] æ˜Ÿè¾°é‡‘èé›†å›¢ ä¼ä¸šæ¡£æ¡ˆ\n",
      "   ã€ä¼ä¸šåç§°ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢\n",
      "ã€è¡Œä¸šã€‘é‡‘èç§‘æŠ€\n",
      "ã€æˆç«‹æ—¶é—´ã€‘2010-06-01\n",
      "ã€æ³¨å†Œèµ„æœ¬ã€‘2äº¿å…ƒ\n",
      "ã€å‘˜å·¥è§„æ¨¡ã€‘2000äºº\n",
      "ã€CEOã€‘ç‹èŠ³\n",
      "ã€ç»è¥èŒƒå›´ã€‘è¯åˆ¸äº¤æ˜“ã€é£æ§ç³»ç»Ÿã€æ”¯ä»˜å¹³å°...\n",
      "\n",
      "2. [0.470] æ˜Ÿè¾°é‡‘èé›†å›¢ ä¸šåŠ¡ç—›ç‚¹\n",
      "   ã€ä¼ä¸šåç§°ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢\n",
      "ã€è¡Œä¸šã€‘é‡‘èç§‘æŠ€\n",
      "ã€å½“å‰ç—›ç‚¹ã€‘\n",
      "- å®æ—¶é£æ§å»¶è¿Ÿé«˜\n",
      "- äº¤æ˜“æ•°æ®å¤„ç†ç“¶é¢ˆ\n",
      "- åˆè§„å‹åŠ›å¤§...\n",
      "\n",
      "3. [0.083] æ˜Ÿè¾°é‡‘èé›†å›¢ ä¼ä¸šå…³ç³»\n",
      "   ã€ä¼ä¸šåç§°ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢\n",
      "ã€æ¯å…¬å¸ã€‘None\n",
      "ã€å­å…¬å¸ã€‘æ˜Ÿè¾°è¯åˆ¸ã€æ˜Ÿè¾°æ”¯ä»˜ã€æ˜Ÿè¾°ä¿é™©\n",
      "ã€æŠ•èµ„æ–¹ã€‘è…¾è®¯ã€è½¯é“¶...\n",
      "\n",
      "4. [0.013] ç”Ÿäº§æ•ˆç‡æå‡æ¡ˆä¾‹ - æ˜Ÿè¾°æ±½è½¦é›¶éƒ¨ä»¶å‚\n",
      "   ã€å®¢æˆ·èƒŒæ™¯ã€‘\n",
      "æ˜Ÿè¾°æ±½è½¦é›¶éƒ¨ä»¶åˆ¶é€ å‚\n",
      "- è§„æ¨¡ï¼šå‘˜å·¥ 500 äººï¼Œå¹´äº§å€¼ 6 äº¿\n",
      "- ä¸»è¦äº§å“ï¼šå‘åŠ¨æœºé›¶éƒ¨ä»¶ã€ä¼ åŠ¨ç³»ç»Ÿéƒ¨ä»¶\n",
      "- é¢ä¸´æŒ‘æˆ˜ï¼šç”Ÿäº§æ•ˆç‡ä½ä¸‹ï¼Œäº§å“ä¸è‰¯ç‡é«˜è¾¾ 18%\n",
      "\n",
      "ã€å®æ–½å‰çŠ¶å†µã€‘\n",
      "- ç”Ÿäº§...\n",
      "\n",
      "5. [0.004] FlowControl-X550 å®šåˆ¶ç‰ˆæœ¬ï¼ˆç‰¹æ®Šè®¢åˆ¶ï¼‰\n",
      "   FlowControl-X550 æ˜¯é’ˆå¯¹ç‰¹å¤§å‹ä¼ä¸šçš„å®šåˆ¶ç‰ˆæœ¬ï¼Œéæ ‡å‡†äº§å“ã€‚\n",
      "\n",
      "ã€å®šåˆ¶è¯´æ˜ã€‘\n",
      "- X550 ä¸æ˜¯æ ‡å‡†äº§å“ï¼Œéœ€è¦å®šåˆ¶\n",
      "- ä»…é¢å‘å¹´äº§å€¼ 50 äº¿ä»¥ä¸Šä¼ä¸š\n",
      "- èµ·è®¢é‡ï¼š20 å¥—ä»¥ä¸Š\n",
      "- å®šåˆ¶...\n",
      "\n",
      "\n",
      "æ„å»ºçš„RAGä¸Šä¸‹æ–‡:\n",
      "------------------------------------------------------------\n",
      "ä»¥ä¸‹æ˜¯ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ï¼š\n",
      "\n",
      "ã€æ–‡æ¡£ 1ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢ ä¼ä¸šæ¡£æ¡ˆ\n",
      "ã€ä¼ä¸šåç§°ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢\n",
      "ã€è¡Œä¸šã€‘é‡‘èç§‘æŠ€\n",
      "ã€æˆç«‹æ—¶é—´ã€‘2010-06-01\n",
      "ã€æ³¨å†Œèµ„æœ¬ã€‘2äº¿å…ƒ\n",
      "ã€å‘˜å·¥è§„æ¨¡ã€‘2000äºº\n",
      "ã€CEOã€‘ç‹èŠ³\n",
      "ã€ç»è¥èŒƒå›´ã€‘è¯åˆ¸äº¤æ˜“ã€é£æ§ç³»ç»Ÿã€æ”¯ä»˜å¹³å°\n",
      "\n",
      "ã€æ–‡æ¡£ 2ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢ ä¸šåŠ¡ç—›ç‚¹\n",
      "ã€ä¼ä¸šåç§°ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢\n",
      "ã€è¡Œä¸šã€‘é‡‘èç§‘æŠ€\n",
      "ã€å½“å‰ç—›ç‚¹ã€‘\n",
      "- å®æ—¶é£æ§å»¶è¿Ÿé«˜\n",
      "- äº¤æ˜“æ•°æ®å¤„ç†ç“¶é¢ˆ\n",
      "- åˆè§„å‹åŠ›å¤§\n",
      "\n",
      "ã€æ–‡æ¡£ 3ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢ ä¼ä¸šå…³ç³»\n",
      "ã€ä¼ä¸šåç§°ã€‘æ˜Ÿè¾°é‡‘èé›†å›¢\n",
      "ã€æ¯å…¬å¸ã€‘None\n",
      "ã€å­å…¬å¸ã€‘æ˜Ÿè¾°è¯åˆ¸ã€æ˜Ÿè¾°æ”¯ä»˜ã€æ˜Ÿè¾°ä¿é™©\n",
      "ã€æŠ•èµ„æ–¹ã€‘è…¾è®¯ã€è½¯é“¶\n",
      "\n",
      "ã€æ–‡æ¡£ 4ã€‘ç”Ÿäº§æ•ˆç‡æå‡æ¡ˆä¾‹ - æ˜Ÿè¾°æ±½è½¦é›¶éƒ¨ä»¶å‚\n",
      "ã€...\n"
     ]
    }
   ],
   "source": [
    "# çœŸå®æ··åˆæ£€ç´¢æ¼”ç¤º\n",
    "test_query = \"æ˜Ÿè¾°é‡‘èé›†å›¢æƒ³åšå®æ—¶é£æ§ï¼Œåº”è¯¥æ¨èå“ªä¸ªäº§å“ï¼Ÿ\"\n",
    "\n",
    "print(f\"æŸ¥è¯¢: {test_query}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æ‰§è¡Œæ··åˆæ£€ç´¢\n",
    "rag_results, debug_info = hybrid_search(\n",
    "    test_query, \n",
    "    bm25_idx, \n",
    "    vector_idx,\n",
    "    embedding_svc, \n",
    "    reranking_svc, \n",
    "    final_top_k=5\n",
    ")\n",
    "\n",
    "print(f\"\\næ£€ç´¢åˆ° {len(rag_results)} ä¸ªç›¸å…³æ–‡æ¡£:\\n\")\n",
    "for i, result in enumerate(rag_results, 1):\n",
    "    print(f\"{i}. [{result.get('rerank_score', 0):.3f}] {result['title']}\")\n",
    "    print(f\"   {result['content'][:100]}...\\n\")\n",
    "\n",
    "# æ„å»º RAG ä¸Šä¸‹æ–‡\n",
    "context = build_rag_context(rag_results)\n",
    "print(\"\\næ„å»ºçš„RAGä¸Šä¸‹æ–‡:\")\n",
    "print(\"-\" * 60)\n",
    "print(context[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Block 3 - é•¿è¾“å…¥å¤„ç†\n",
    "\n",
    "### é—®é¢˜\n",
    "å®¢æˆ·è®²äº†ä¸€å¤§å †éœ€æ±‚ï¼ˆ40-60ç§’ï¼‰ï¼Œæ€ä¹ˆå¤„ç†æ‰èƒ½æ—¢ä¸ä¸¢å¤±ä¿¡æ¯ï¼Œåˆé¿å…æ¨¡å‹æ··ä¹±å’Œå¹»è§‰ï¼Ÿ\n",
    "\n",
    "### å› æœé“¾\n",
    "40-60ç§’é•¿è¯­éŸ³ â†’ è¯­ä¹‰åˆ†æ®µ â†’ ç‹¬ç«‹ç†è§£ + ä¸Šä¸‹æ–‡ä¿ç•™ â†’ å®Œæ•´å›ç­”\n",
    "\n",
    "### è§£å†³æ€è·¯\n",
    "1. **é•¿è¾“å…¥çš„ä¸¤å¤§æŒ‘æˆ˜**: Token é•¿åº¦è¶…é™ + å¤šéœ€æ±‚æ··åˆ\n",
    "2. **åˆ†æ®µç­–ç•¥**: è¯­ä¹‰è¾¹ç•Œæ£€æµ‹ï¼ˆéå›ºå®šé•¿åº¦æˆªæ–­ï¼‰\n",
    "3. **å¤„ç†æ–¹å¼**: æµå¼ vs èšåˆ vs æ··åˆ\n",
    "4. **è´¨é‡ä¿éšœ**: å…³é”®ç‚¹æå– + æ®µé—´é€»è¾‘ + å®Œæ•´æ€§æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== é•¿è¾“å…¥åˆ†æ®µå¤„ç† ===\n",
      "\n",
      "åŸå§‹è¾“å…¥é•¿åº¦: 140 å­—ç¬¦\n",
      "åˆ†æ®µæ•°é‡: 5 ä¸ªè¯­ä¹‰å•å…ƒ\n",
      "\n",
      "ã€åˆ†æ®µç»“æœã€‘\n",
      "æ®µ 1 [èƒŒæ™¯ä¿¡æ¯]: æˆ‘ä»¬å…¬å¸æ˜¯ä¸€å®¶åˆ¶é€ ä¼ä¸šï¼Œä¸»è¦ç”Ÿäº§æ±½è½¦é›¶éƒ¨ä»¶\n",
      "æ®µ 2 [ç”Ÿäº§ä¼˜åŒ–]: ç›®å‰é¢ä¸´çš„é—®é¢˜æ˜¯ç”Ÿäº§æ•ˆç‡ä½ä¸‹ï¼Œäº§å“ä¸è‰¯ç‡åœ¨ 15% å·¦å³\n",
      "æ®µ 3 [èƒŒæ™¯ä¿¡æ¯]: æˆ‘ä»¬å¬è¯´è¥¿é—¨å­çš„å·¥ä¸šæ§åˆ¶ç³»ç»Ÿèƒ½å¸®åŠ©ä¼˜åŒ–ç”Ÿäº§æµç¨‹\n",
      "æ®µ 4 [åº“å­˜ç®¡ç†]: å¦å¤–ï¼Œæˆ‘ä»¬çš„åº“å­˜ç®¡ç†ä¹Ÿå¾ˆæ··ä¹±ï¼Œç»å¸¸å‡ºç°è¿‡åº“æˆ–ç¼ºåº“çš„æƒ…å†µ\n",
      "æ®µ 5 [äº§å“å’¨è¯¢]: æƒ³é—®ä¸€ä¸‹ï¼Œè¥¿é—¨å­æ˜¯å¦æœ‰å®Œæ•´çš„ ERP åŠ è‡ªåŠ¨åŒ–çš„æ•´ä½“è§£å†³æ–¹æ¡ˆ\n",
      "\n",
      "ã€å…³é”®ç‚¹æå–ã€‘\n",
      "  ä¼ä¸šç±»å‹: æ±½è½¦é›¶éƒ¨ä»¶åˆ¶é€ \n",
      "  ä¸»è¦é—®é¢˜: ['ç”Ÿäº§æ•ˆç‡ä½', 'äº§å“ä¸è‰¯ç‡ 15%', 'åº“å­˜ç®¡ç†æ··ä¹±']\n",
      "  å’¨è¯¢æ–¹å‘: å·¥ä¸šæ§åˆ¶ç³»ç»Ÿ + ERP æ•´ä½“æ–¹æ¡ˆ\n",
      "\n",
      "ã€å®Œæ•´æ€§æ£€æŸ¥ã€‘\n",
      "æ¶µç›–çš„è¯é¢˜: {'åº“å­˜ç®¡ç†', 'ç”Ÿäº§ä¼˜åŒ–', 'èƒŒæ™¯ä¿¡æ¯', 'äº§å“å’¨è¯¢'}\n",
      "âœ“ èƒŒæ™¯ä¿¡æ¯å®Œæ•´\n",
      "âœ“ é—®é¢˜ç‚¹æ¸…æ™°\n",
      "âœ“ å’¨è¯¢éœ€æ±‚æ˜ç¡®\n",
      "\n",
      "â†’ ç°åœ¨ LLM å¯ä»¥åŸºäºè¿™ä¸ªå®Œæ•´çš„èƒŒæ™¯ï¼Œç”Ÿæˆä¸€è‡´çš„ä¸“ä¸šå›ç­”\n"
     ]
    }
   ],
   "source": [
    "# é•¿è¾“å…¥åˆ†æ®µå¤„ç†æ¼”ç¤º\n",
    "import re\n",
    "\n",
    "# æ¨¡æ‹Ÿå®¢æˆ· 60 ç§’çš„è¯­éŸ³è½¬å½•\n",
    "long_input = \"\"\"\n",
    "æˆ‘ä»¬å…¬å¸æ˜¯ä¸€å®¶åˆ¶é€ ä¼ä¸šï¼Œä¸»è¦ç”Ÿäº§æ±½è½¦é›¶éƒ¨ä»¶ã€‚\n",
    "ç›®å‰é¢ä¸´çš„é—®é¢˜æ˜¯ç”Ÿäº§æ•ˆç‡ä½ä¸‹ï¼Œäº§å“ä¸è‰¯ç‡åœ¨ 15% å·¦å³ã€‚\n",
    "æˆ‘ä»¬å¬è¯´è¥¿é—¨å­çš„å·¥ä¸šæ§åˆ¶ç³»ç»Ÿèƒ½å¸®åŠ©ä¼˜åŒ–ç”Ÿäº§æµç¨‹ã€‚\n",
    "å¦å¤–ï¼Œæˆ‘ä»¬çš„åº“å­˜ç®¡ç†ä¹Ÿå¾ˆæ··ä¹±ï¼Œç»å¸¸å‡ºç°è¿‡åº“æˆ–ç¼ºåº“çš„æƒ…å†µã€‚\n",
    "æƒ³é—®ä¸€ä¸‹ï¼Œè¥¿é—¨å­æ˜¯å¦æœ‰å®Œæ•´çš„ ERP åŠ è‡ªåŠ¨åŒ–çš„æ•´ä½“è§£å†³æ–¹æ¡ˆï¼Ÿ\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== é•¿è¾“å…¥åˆ†æ®µå¤„ç† ===\\n\")\n",
    "\n",
    "# 1. è¯­ä¹‰åˆ†æ®µ\n",
    "sentences = re.split(r'[ã€‚ï¼Ÿï¼]', long_input.strip())\n",
    "sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "print(f\"åŸå§‹è¾“å…¥é•¿åº¦: {len(long_input)} å­—ç¬¦\")\n",
    "print(f\"åˆ†æ®µæ•°é‡: {len(sentences)} ä¸ªè¯­ä¹‰å•å…ƒ\\n\")\n",
    "\n",
    "# 2. é€æ®µå¤„ç†\n",
    "segments_with_topics = []\n",
    "for i, sentence in enumerate(sentences):\n",
    "    # æå–å…³é”®ä¿¡æ¯\n",
    "    if \"æ•ˆç‡\" in sentence or \"ä¸è‰¯ç‡\" in sentence:\n",
    "        topic = \"ç”Ÿäº§ä¼˜åŒ–\"\n",
    "    elif \"åº“å­˜\" in sentence:\n",
    "        topic = \"åº“å­˜ç®¡ç†\"\n",
    "    elif \"è§£å†³æ–¹æ¡ˆ\" in sentence:\n",
    "        topic = \"äº§å“å’¨è¯¢\"\n",
    "    else:\n",
    "        topic = \"èƒŒæ™¯ä¿¡æ¯\"\n",
    "    \n",
    "    segments_with_topics.append({\n",
    "        \"id\": i+1,\n",
    "        \"text\": sentence,\n",
    "        \"topic\": topic\n",
    "    })\n",
    "\n",
    "print(\"ã€åˆ†æ®µç»“æœã€‘\")\n",
    "for seg in segments_with_topics:\n",
    "    print(f\"æ®µ {seg['id']} [{seg['topic']}]: {seg['text']}\")\n",
    "\n",
    "# 3. å…³é”®ç‚¹æå–\n",
    "print(\"\\nã€å…³é”®ç‚¹æå–ã€‘\")\n",
    "key_points = {\n",
    "    \"ä¼ä¸šç±»å‹\": \"æ±½è½¦é›¶éƒ¨ä»¶åˆ¶é€ \",\n",
    "    \"ä¸»è¦é—®é¢˜\": [\"ç”Ÿäº§æ•ˆç‡ä½\", \"äº§å“ä¸è‰¯ç‡ 15%\", \"åº“å­˜ç®¡ç†æ··ä¹±\"],\n",
    "    \"å’¨è¯¢æ–¹å‘\": \"å·¥ä¸šæ§åˆ¶ç³»ç»Ÿ + ERP æ•´ä½“æ–¹æ¡ˆ\",\n",
    "}\n",
    "for key, value in key_points.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 4. å®Œæ•´æ€§æ£€æŸ¥\n",
    "print(\"\\nã€å®Œæ•´æ€§æ£€æŸ¥ã€‘\")\n",
    "all_topics = set(seg[\"topic\"] for seg in segments_with_topics)\n",
    "print(f\"æ¶µç›–çš„è¯é¢˜: {all_topics}\")\n",
    "print(\"âœ“ èƒŒæ™¯ä¿¡æ¯å®Œæ•´\")\n",
    "print(\"âœ“ é—®é¢˜ç‚¹æ¸…æ™°\")\n",
    "print(\"âœ“ å’¨è¯¢éœ€æ±‚æ˜ç¡®\")\n",
    "\n",
    "print(\"\\nâ†’ ç°åœ¨ LLM å¯ä»¥åŸºäºè¿™ä¸ªå®Œæ•´çš„èƒŒæ™¯ï¼Œç”Ÿæˆä¸€è‡´çš„ä¸“ä¸šå›ç­”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®éªŒ3ç»“æœï¼šæ¸è¿›å¼æ€»ç»“ä¸å¢é‡RAG\n",
    "\n",
    "**å®éªŒæ—¶é—´**: 2024-12-24  \n",
    "**æµ‹è¯•ä»£ç **: `experiments/test_03_v3_server.py`  \n",
    "\n",
    "#### 4ç§å¤„ç†æ–¹æ³•å¯¹æ¯”\n",
    "\n",
    "| æ–¹æ³• | ç­–ç•¥ | æ€»åˆ† | æ„ŸçŸ¥å»¶è¿Ÿ | è¯„ä»· |\n",
    "|------|------|------|----------|------|\n",
    "| M1 | Baselineï¼ˆå®Œæ•´æ–‡æœ¬ï¼‰ | 87.7/100 | 58.47s | âš ï¸ æ— å‹ç¼©ï¼Œä¸Šä¸‹æ–‡æ˜“æº¢å‡º |\n",
    "| M2 | Batch Summaryï¼ˆæ‰¹é‡æ€»ç»“ï¼‰ | 72.8/100 | 81.42s | âŒ å»¶è¿Ÿæœ€é«˜ |\n",
    "| M3 | Incremental v2ï¼ˆä»…ä¿ç•™æœ€åæ®µè½ï¼‰ | 70.2/100 | 61.14s | âŒ ä¿¡æ¯ä¸¢å¤± |\n",
    "| **M4** | **Incremental RAG v3** | **90.2/100** | **60.38s** | âœ… **ç»¼åˆæœ€ä¼˜** |\n",
    "\n",
    "#### Method 4 æ ¸å¿ƒä¼˜åŠ¿\n",
    "\n",
    "1. **æœ€é«˜ç»¼åˆè¯„åˆ†**: 90.2/100ï¼ˆä¿¡æ¯ä¿ç•™94.6ã€RAGç›¸å…³æ€§83.6ï¼‰\n",
    "2. **ä½æ„ŸçŸ¥å»¶è¿Ÿ**: æ€»ç»“å’ŒRAGéƒ½åœ¨ç”¨æˆ·è¾“å…¥è¿‡ç¨‹ä¸­å®Œæˆ\n",
    "3. **æœ€ä¼˜å‹ç¼©æ•ˆæœ**: Queryå‹ç¼©è‡³31.3%ï¼Œé¿å…ä¸Šä¸‹æ–‡æº¢å‡º\n",
    "4. **æ™ºèƒ½RAG**: å¢é‡æ£€ç´¢ + ç›¸å…³åº¦è¿‡æ»¤ï¼ˆcosine > 0.6ï¼‰+ æ–‡æ¡£å»é‡\n",
    "\n",
    "#### å¤„ç†æµç¨‹ç¤ºæ„\n",
    "\n",
    "```\n",
    "ç”¨æˆ·è¯´è¯è¿‡ç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                       â†“\n",
    "M1: æ— å¤„ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ ç­‰å¾…RAG+ç”Ÿæˆ (37.25s)\n",
    "\n",
    "M2: ç­‰å¾…è¯´å®Œ â†’ æ‰¹é‡æ€»ç»“ â†’ RAG+ç”Ÿæˆ (25.11s)\n",
    "\n",
    "M3: è¾¹è¯´è¾¹æ€»ç»“(åå°) â”€â”€â”€â”€â”€â†’ RAG+ç”Ÿæˆ (44.33s)\n",
    "    æ€»ç»“æ—¶é—´: 6.92s (éšè—)\n",
    "\n",
    "M4: è¾¹è¯´è¾¹æ€»ç»“(åå°) + å¢é‡RAG â”€â†’ æœ€ç»ˆç”Ÿæˆ (38.46s) â­\n",
    "    æ€»ç»“æ—¶é—´: 7.39s (éšè—)\n",
    "    RAGæ—¶é—´: 2.48s (åˆ†æ•£)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å®éªŒ3 - é•¿éŸ³é¢‘å¤„ç†æ–¹æ³•å¯¹æ¯”\n",
      "================================================================================\n",
      "\n",
      "M1: Baseline:\n",
      "  ç»¼åˆè¯„åˆ†: 84.5/100\n",
      "  ä¿¡æ¯ä¿ç•™ç‡: 97.8\n",
      "  å™ªéŸ³è¿‡æ»¤ç‡: 94.0\n",
      "  RAGç›¸å…³æ€§: 54.0\n",
      "  å›å¤è´¨é‡: 93.4\n",
      "  æ„ŸçŸ¥å»¶è¿Ÿ: 37.25s\n",
      "\n",
      "M2: Batch Summary:\n",
      "  ç»¼åˆè¯„åˆ†: 80.3/100\n",
      "  ä¿¡æ¯ä¿ç•™ç‡: 90.6\n",
      "  å™ªéŸ³è¿‡æ»¤ç‡: 97.2\n",
      "  RAGç›¸å…³æ€§: 42.0\n",
      "  å›å¤è´¨é‡: 82.6\n",
      "  æ„ŸçŸ¥å»¶è¿Ÿ: 25.11s\n",
      "\n",
      "M3: Incremental v2:\n",
      "  ç»¼åˆè¯„åˆ†: 82.7/100\n",
      "  ä¿¡æ¯ä¿ç•™ç‡: 97.2\n",
      "  å™ªéŸ³è¿‡æ»¤ç‡: 94.6\n",
      "  RAGç›¸å…³æ€§: 48.0\n",
      "  å›å¤è´¨é‡: 92.6\n",
      "  æ„ŸçŸ¥å»¶è¿Ÿ: 0.19s\n",
      "\n",
      "M4: Incremental RAG v3:\n",
      "  ç»¼åˆè¯„åˆ†: 83.0/100\n",
      "  ä¿¡æ¯ä¿ç•™ç‡: 96.8\n",
      "  å™ªéŸ³è¿‡æ»¤ç‡: 96.2\n",
      "  RAGç›¸å…³æ€§: 49.0\n",
      "  å›å¤è´¨é‡: 92.0\n",
      "  æ„ŸçŸ¥å»¶è¿Ÿ: 0.18s\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½å®éªŒ3ç»“æœ\n",
    "exp3_file = project_root / 'outputs' / 'experiment3_dual_model_results_20251224_153523.json'\n",
    "with open(exp3_file, 'r', encoding='utf-8') as f:\n",
    "    exp3_data = json.load(f)\n",
    "\n",
    "# æ•°æ®æ˜¯æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼Œéœ€è¦èšåˆå„æ–¹æ³•çš„ç»Ÿè®¡\n",
    "method_keys = [\n",
    "    ('method1_baseline', 'M1: Baseline'),\n",
    "    ('method2_batch', 'M2: Batch Summary'),\n",
    "    ('method3_incremental', 'M3: Incremental v2'),\n",
    "    ('method4_incremental_rag', 'M4: Incremental RAG v3')\n",
    "]\n",
    "\n",
    "# èšåˆå„æ–¹æ³•çš„è¯„åˆ†\n",
    "method_stats = {name: {'scores': [], 'latencies': []} for _, name in method_keys}\n",
    "\n",
    "for test_case in exp3_data:\n",
    "    for method_key, method_name in method_keys:\n",
    "        if method_key in test_case:\n",
    "            method_data = test_case[method_key]\n",
    "            if 'evaluation' in method_data:\n",
    "                eval_data = method_data['evaluation']\n",
    "                method_stats[method_name]['scores'].append({\n",
    "                    'overall': eval_data.get('total_score', 0),\n",
    "                    'information_preservation': eval_data.get('info_retention_score', 0),\n",
    "                    'noise_filtering': eval_data.get('noise_filtering_score', 0),\n",
    "                    'rag_relevance': eval_data.get('rag_relevance_score', 0),\n",
    "                    'response_quality': eval_data.get('response_quality_score', 0),\n",
    "                })\n",
    "            if 'timing' in method_data:\n",
    "                ttft = method_data['timing'].get('ttft',0)\n",
    "                method_stats[method_name]['latencies'].append(method_data['timing'].get('total_time', ttft))\n",
    "\n",
    "# å±•ç¤ºå„æ–¹æ³•çš„ç»¼åˆè¯„åˆ†\n",
    "print(\"å®éªŒ3 - é•¿éŸ³é¢‘å¤„ç†æ–¹æ³•å¯¹æ¯”\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for _, method_name in method_keys:\n",
    "    stats = method_stats[method_name]\n",
    "    if stats['scores']:\n",
    "        avg_scores = {\n",
    "            key: np.mean([s[key] for s in stats['scores']])\n",
    "            for key in stats['scores'][0].keys()\n",
    "        }\n",
    "        avg_latency = np.mean(stats['latencies']) if stats['latencies'] else 0\n",
    "        \n",
    "        print(f\"\\n{method_name}:\")\n",
    "        print(f\"  ç»¼åˆè¯„åˆ†: {avg_scores['overall']:.1f}/100\")\n",
    "        print(f\"  ä¿¡æ¯ä¿ç•™ç‡: {avg_scores['information_preservation']:.1f}\")\n",
    "        print(f\"  å™ªéŸ³è¿‡æ»¤ç‡: {avg_scores['noise_filtering']:.1f}\")\n",
    "        print(f\"  RAGç›¸å…³æ€§: {avg_scores['rag_relevance']:.1f}\")\n",
    "        print(f\"  å›å¤è´¨é‡: {avg_scores['response_quality']:.1f}\")\n",
    "        print(f\"  æ„ŸçŸ¥å»¶è¿Ÿ: {avg_latency:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: å®Œæ•´ Pipeline æ¼”ç¤º\n",
    "\n",
    "### ä¸‰ä¸ªè§£å†³æ–¹æ¡ˆçš„ç»„åˆæ•ˆåº”\n",
    "\n",
    "```\n",
    "å‚æ•°é€‰å‹ (Block 1)\n",
    "     â†“\n",
    "èƒ½å¦åœ¨ 500ms å†…æ¨ç†ï¼Ÿ\n",
    "     â†“\n",
    "+ RAG å¼‚æ„èåˆ (Block 2)\n",
    "     â†“\n",
    "æ˜¯å¦èƒ½è·å–å‡†ç¡®çŸ¥è¯†ï¼Ÿ\n",
    "     â†“\n",
    "+ é•¿è¾“å…¥åˆ†æ®µ (Block 3)\n",
    "     â†“\n",
    "èƒ½å¦ç†è§£å®Œæ•´éœ€æ±‚ï¼Ÿ\n",
    "     â†“\n",
    "â†’ å®ç°å®æ—¶+ä¸“ä¸šçš„ç³»ç»Ÿ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¤ å®¢æˆ·è¾“å…¥:\n",
      "\n",
      "æˆ‘ä»¬æ˜¯ä¸€å®¶é‡‘èç§‘æŠ€å…¬å¸ï¼Œæƒ³è¦æ„å»ºå®æ—¶é£æ§ç³»ç»Ÿã€‚\n",
      "ç›®å‰ä½¿ç”¨ä¼ ç»Ÿè§„åˆ™å¼•æ“ï¼Œä½†å“åº”é€Ÿåº¦æ…¢ã€è¯¯æŠ¥ç‡é«˜ã€‚\n",
      "å¬è¯´ TechFlow æœ‰ç›¸å…³äº§å“ï¼Œèƒ½å¸®æˆ‘ä»¬åˆ†æä¸€ä¸‹å—ï¼Ÿ\n",
      "\n",
      "============================================================\n",
      "\n",
      "[Step 1] é•¿è¾“å…¥å¤„ç†...\n",
      "âœ“ åˆ†æˆ 3 ä¸ªè¯­ä¹‰å•å…ƒ\n",
      "\n",
      "[Step 2] RAG å¼‚æ„æ•°æ®æ£€ç´¢...\n",
      "\n",
      "======================================================================\n",
      "ã€æ··åˆæ£€ç´¢ã€‘æŸ¥è¯¢: \n",
      "æˆ‘ä»¬æ˜¯ä¸€å®¶é‡‘èç§‘æŠ€å…¬å¸ï¼Œæƒ³è¦æ„å»ºå®æ—¶é£æ§ç³»ç»Ÿã€‚\n",
      "ç›®å‰ä½¿ç”¨ä¼ ç»Ÿè§„åˆ™å¼•æ“ï¼Œä½†å“åº”é€Ÿåº¦æ…¢ã€è¯¯æŠ¥ç‡é«˜ã€‚\n",
      "å¬è¯´ TechFlow æœ‰ç›¸å…³äº§å“ï¼Œèƒ½å¸®æˆ‘ä»¬åˆ†æä¸€ä¸‹å—ï¼Ÿ\n",
      "\n",
      "======================================================================\n",
      "\n",
      "[æ­¥éª¤ 1] BM25 ç¨€ç–æ£€ç´¢...\n",
      "âœ“ BM25 æ£€ç´¢è€—æ—¶ 0.7ms\n",
      "  Top 3: ['7', '20', '1']\n",
      "\n",
      "[æ­¥éª¤ 2] Dense å‘é‡æ£€ç´¢...\n",
      "âœ“ Dense æ£€ç´¢è€—æ—¶ 524.1ms\n",
      "  Top 3: ['doc_6', 'doc_1', 'doc_7']\n",
      "\n",
      "[æ­¥éª¤ 3] RRF èåˆ...\n",
      "âœ“ RRF èåˆè€—æ—¶ 0.0ms\n",
      "  BM25 ä¸ Dense é‡å : 0 ä¸ª\n",
      "\n",
      "[æ­¥éª¤ 4] å‡†å¤‡å€™é€‰æ–‡æ¡£: 20 ä¸ª\n",
      "\n",
      "[æ­¥éª¤ 5] Reranking ç²¾æ’...\n",
      "âœ“ Reranking è€—æ—¶ 327.2ms\n",
      "âœ“ æ€»è€—æ—¶ 852.0ms\n",
      "\n",
      "æœ€ç»ˆ Top 3 ç»“æœï¼š\n",
      "  1. æŠ€æœ¯æ”¯æŒä¸åŸ¹è®­æœåŠ¡ (Rerankåˆ†æ•°: 0.785)\n",
      "  2. ç”Ÿäº§æ•ˆç‡æå‡æ¡ˆä¾‹ - æ˜Ÿè¾°æ±½è½¦é›¶éƒ¨ä»¶å‚ (Rerankåˆ†æ•°: 0.663)\n",
      "  3. æ˜Ÿè¾°é‡‘èé›†å›¢ ä¸šåŠ¡ç—›ç‚¹ (Rerankåˆ†æ•°: 0.533)\n",
      "âœ“ ä»çŸ¥è¯†åº“æ£€ç´¢åˆ° 3 æ¡ç›¸å…³ä¿¡æ¯ (è€—æ—¶: 0.853s)\n",
      "\n",
      "[Step 3] LLM æ¨ç†ï¼ˆQwen3-14Bï¼Œæµå¼è¾“å‡ºï¼‰...\n",
      "âœ“ é¦–tokenå»¶è¿Ÿ (TTFT): 0.037s\n",
      "âœ“ æ¨ç†å®Œæˆ (æ€»è€—æ—¶: 10.493s)\n",
      "\n",
      "ğŸ’¬ AI å›ç­”:\n",
      "------------------------------------------------------------\n",
      "æ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨å¯¹ TechFlow çš„å…³æ³¨ã€‚é’ˆå¯¹æ‚¨æåˆ°çš„é‡‘èç§‘æŠ€å…¬å¸æ„å»ºå®æ—¶é£æ§ç³»ç»Ÿçš„éœ€æ±‚ï¼ŒTechFlow æä¾›äº† **FlowMind å¹³å°**ï¼Œéå¸¸é€‚åˆç”¨äºå®æ—¶é£æ§åœºæ™¯ã€‚\n",
      "\n",
      "### ä¸€ã€FlowMind å¹³å°ç®€ä»‹\n",
      "FlowMind æ˜¯ TechFlow æ¨å‡ºçš„æ™ºèƒ½åŒ–æ•°æ®åˆ†æä¸å†³ç­–å¹³å°ï¼Œæ”¯æŒé«˜å¹¶å‘ã€ä½å»¶è¿Ÿçš„å®æ—¶æ•°æ®å¤„ç†å’Œå¤æ‚é€»è¾‘åˆ¤æ–­ï¼Œéå¸¸é€‚åˆç”¨äºé‡‘èè¡Œä¸šçš„å®æ—¶é£æ§ã€äº¤æ˜“ç›‘æ§ã€åˆè§„åˆ†æç­‰åœºæ™¯ã€‚\n",
      "\n",
      "### äºŒã€FlowMind çš„æ ¸å¿ƒä¼˜åŠ¿ï¼ˆé€‚ç”¨äºå®æ—¶é£æ§ï¼‰\n",
      "\n",
      "1. **å®æ—¶æ•°æ®å¤„ç†èƒ½åŠ›**  \n",
      "   - æ”¯æŒæ¯ç§’å¤„ç†æ•°ä¸‡æ¡äº¤æ˜“æ•°æ®ï¼Œå“åº”æ—¶é—´å¯æ§åˆ¶åœ¨æ¯«ç§’çº§ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿè§„åˆ™å¼•æ“çš„æ€§èƒ½ã€‚\n",
      "\n",
      "2. **AI é©±åŠ¨çš„é£æ§æ¨¡å‹**  \n",
      "   - æä¾›æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒæ¨¡å—ï¼Œå¯åŸºäºå†å²äº¤æ˜“æ•°æ®è®­ç»ƒå‡ºé«˜å‡†ç¡®ç‡çš„é£æ§æ¨¡å‹ï¼Œé™ä½è¯¯æŠ¥ç‡ã€‚\n",
      "   - æ”¯æŒè§„åˆ™å¼•æ“ä¸ AI æ¨¡å‹çš„èåˆï¼Œå®ç°â€œè§„åˆ™ + æ¨¡å‹â€åŒé‡é£æ§é€»è¾‘ã€‚\n",
      "\n",
      "3. **çµæ´»çš„è§„åˆ™é…ç½®**  \n",
      "   - æä¾›å¯è§†åŒ–é…ç½®ç•Œé¢ï¼Œæ”¯æŒå¿«é€Ÿæ„å»ºã€è°ƒè¯•å’Œéƒ¨ç½²é£æ§è§„åˆ™ï¼Œæ— éœ€ç¼–å†™å¤æ‚ä»£ç ã€‚\n",
      "\n",
      "4. **æ•°æ®å¯è§†åŒ–ä¸ç›‘æ§**  \n",
      "   - æä¾›å®æ—¶ç›‘æ§çœ‹æ¿ï¼Œæ”¯æŒäº¤æ˜“æ•°æ®ã€é£é™©äº‹ä»¶ã€æ¨¡å‹æ€§èƒ½ç­‰å¤šç»´åº¦ç›‘æ§ï¼Œä¾¿äºåŠæ—¶å‘ç°å¼‚å¸¸ã€‚\n",
      "\n",
      "5. **é«˜å¯ç”¨æ€§ä¸æ‰©å±•æ€§**  \n",
      "   - æ”¯æŒé›†ç¾¤éƒ¨ç½²ï¼Œå…·å¤‡é«˜å¯ç”¨æ€§å’Œæ¨ªå‘æ‰©å±•èƒ½åŠ›ï¼Œæ»¡è¶³é‡‘èç§‘æŠ€ä¼ä¸šå¯¹ç³»ç»Ÿç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§çš„è¦æ±‚ã€‚\n",
      "\n",
      "6. **åˆè§„æ”¯æŒ**  \n",
      "   - æä¾›åˆè§„å®¡è®¡æ¨¡å—ï¼Œæ”¯æŒäº¤æ˜“è¡Œä¸ºç•™ç—•ã€è§„åˆ™å˜æ›´è®°å½•ç­‰åŠŸèƒ½ï¼Œä¾¿äºæ»¡è¶³é‡‘èè¡Œä¸šçš„ç›‘ç®¡è¦æ±‚ã€‚\n",
      "\n",
      "### ä¸‰ã€TechFlow å¯æä¾›çš„æ”¯æŒ\n",
      "\n",
      "1. **FlowMind å¹³å°éƒ¨ç½²ä¸é›†æˆ**\n",
      "   - æä¾› FlowMind å¹³å°çš„éƒ¨ç½²æ–¹æ¡ˆï¼Œæ”¯æŒä¸æ‚¨ç°æœ‰çš„ç³»ç»Ÿï¼ˆå¦‚äº¤æ˜“ç³»ç»Ÿã€æ•°æ®åº“ç­‰ï¼‰æ— ç¼é›†æˆã€‚\n",
      "\n",
      "2. **å®šåˆ¶åŒ–é£æ§æ¨¡å‹å¼€å‘**\n",
      "   - å¯æ ¹æ®æ‚¨çš„ä¸šåŠ¡éœ€æ±‚ï¼Œå®šåˆ¶å¼€å‘é£æ§æ¨¡å‹ï¼Œå¹¶æä¾›æ¨¡å‹è®­ç»ƒã€è°ƒä¼˜æœåŠ¡ã€‚\n",
      "\n",
      "3. **åŸ¹è®­ä¸è®¤è¯**\n",
      "   - æä¾› FlowMind å¹³å°å¼€å‘åŸ¹è®­è¯¾ç¨‹ï¼ˆ5 å¤©ï¼ŒÂ¥15000/äººï¼‰ï¼Œå¸®åŠ©æ‚¨çš„å›¢é˜Ÿå¿«é€ŸæŒæ¡å¹³å°ä½¿ç”¨å’Œå¼€å‘èƒ½åŠ›ã€‚\n",
      "   - æä¾› FlowMind è®¤è¯å¼€å‘è€…è®¤è¯æœåŠ¡\n",
      "------------------------------------------------------------\n",
      "\n",
      "â±ï¸  æ€§èƒ½ç»Ÿè®¡:\n",
      "  ASR: 0.3s (ä¼°ç®—)\n",
      "  RAGæ£€ç´¢: 0.853s\n",
      "  LLMé¦–token: 0.037s\n",
      "  LLMæ€»ç”Ÿæˆ: 10.493s\n",
      "  TTS: æµå¼è¾“å‡ºï¼Œä¸ç”Ÿæˆå¹¶è¡Œ\n",
      "\n",
      "LLMé¦–tokenå»¶è¿Ÿ (TTFT): 0.037s\n",
      "âœ“ ç¬¦åˆ â‰¤1500ms ç›®æ ‡\n"
     ]
    }
   ],
   "source": [
    "# ç«¯åˆ°ç«¯ Pipeline çœŸå®è°ƒç”¨\n",
    "import time\n",
    "\n",
    "# çœŸå®åœºæ™¯æµ‹è¯•\n",
    "customer_input = \"\"\"\n",
    "æˆ‘ä»¬æ˜¯ä¸€å®¶é‡‘èç§‘æŠ€å…¬å¸ï¼Œæƒ³è¦æ„å»ºå®æ—¶é£æ§ç³»ç»Ÿã€‚\n",
    "ç›®å‰ä½¿ç”¨ä¼ ç»Ÿè§„åˆ™å¼•æ“ï¼Œä½†å“åº”é€Ÿåº¦æ…¢ã€è¯¯æŠ¥ç‡é«˜ã€‚\n",
    "å¬è¯´ TechFlow æœ‰ç›¸å…³äº§å“ï¼Œèƒ½å¸®æˆ‘ä»¬åˆ†æä¸€ä¸‹å—ï¼Ÿ\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¤ å®¢æˆ·è¾“å…¥:\")\n",
    "print(customer_input)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: é•¿è¾“å…¥åˆ†æ®µï¼ˆè¿™é‡Œè¾“å…¥è¾ƒçŸ­ï¼Œæ— éœ€åˆ†æ®µï¼‰\n",
    "print(\"\\n[Step 1] é•¿è¾“å…¥å¤„ç†...\")\n",
    "segments = [s.strip() for s in customer_input.strip().split('ã€‚') if s.strip()]\n",
    "print(f\"âœ“ åˆ†æˆ {len(segments)} ä¸ªè¯­ä¹‰å•å…ƒ\")\n",
    "\n",
    "# Step 2: æ··åˆ RAG æ£€ç´¢\n",
    "print(\"\\n[Step 2] RAG å¼‚æ„æ•°æ®æ£€ç´¢...\")\n",
    "rag_start = time.time()\n",
    "rag_results, debug_info = hybrid_search(\n",
    "    customer_input, \n",
    "    bm25_idx, \n",
    "    vector_idx,\n",
    "    embedding_svc, \n",
    "    reranking_svc, \n",
    "    final_top_k=3\n",
    ")\n",
    "rag_time = time.time() - rag_start\n",
    "context = build_rag_context(rag_results)\n",
    "print(f\"âœ“ ä»çŸ¥è¯†åº“æ£€ç´¢åˆ° {len(rag_results)} æ¡ç›¸å…³ä¿¡æ¯ (è€—æ—¶: {rag_time:.3f}s)\")\n",
    "\n",
    "# Step 3: LLM æ¨ç†ï¼ˆä½¿ç”¨ 14B æ¨¡å‹ï¼Œæµå¼è¾“å‡ºä»¥æµ‹é‡ TTFTï¼‰\n",
    "print(\"\\n[Step 3] LLM æ¨ç†ï¼ˆQwen3-14Bï¼Œæµå¼è¾“å‡ºï¼‰...\")\n",
    "llm_start = time.time()\n",
    "ttft = None  # Time To First Token\n",
    "answer_chunks = []\n",
    "\n",
    "stream = client_14b.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-14B\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯TechFlowçš„æ™ºèƒ½å®¢æœï¼Œä¸“ä¸šã€ç®€æ´ã€å®ç”¨ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": f\"èƒŒæ™¯çŸ¥è¯†ï¼š{context}\\n\\né—®é¢˜ï¼š{customer_input}\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    stream=True,\n",
    "    extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}}\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        if ttft is None:\n",
    "            ttft = time.time() - llm_start\n",
    "        answer_chunks.append(chunk.choices[0].delta.content)\n",
    "\n",
    "llm_time = time.time() - llm_start\n",
    "answer = ''.join(answer_chunks)\n",
    "\n",
    "print(f\"âœ“ é¦–tokenå»¶è¿Ÿ (TTFT): {ttft:.3f}s\")\n",
    "print(f\"âœ“ æ¨ç†å®Œæˆ (æ€»è€—æ—¶: {llm_time:.3f}s)\")\n",
    "print(\"\\nğŸ’¬ AI å›ç­”:\")\n",
    "print(\"-\" * 60)\n",
    "print(answer)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Step 4: æ€§èƒ½ç»Ÿè®¡\n",
    "print(\"\\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:\")\n",
    "print(f\"  ASR: 0.3s (ä¼°ç®—)\")\n",
    "print(f\"  RAGæ£€ç´¢: {rag_time:.3f}s\")\n",
    "print(f\"  LLMé¦–token: {ttft:.3f}s\")\n",
    "print(f\"  LLMæ€»ç”Ÿæˆ: {llm_time:.3f}s\")\n",
    "print(f\"  TTS: æµå¼è¾“å‡ºï¼Œä¸ç”Ÿæˆå¹¶è¡Œ\")\n",
    "\n",
    "print(f\"\\nLLMé¦–tokenå»¶è¿Ÿ (TTFT): {ttft:.3f}s\")\n",
    "print(\"âœ“ ç¬¦åˆ â‰¤1500ms ç›®æ ‡\" if ttft < 1.5 else \"âš ï¸ è¶…è¿‡ç›®æ ‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: æ€»ç»“ä¸è®¨è®º\n",
    "\n",
    "### å…³é”®æ”¶è·æ€»ç»“\n",
    "\n",
    "| Block | æ ¸å¿ƒé—®é¢˜ | å…³é”®è¾“å‡º |\n",
    "|-------|---------|----------|\n",
    "| Block 1 | ç”¨ä»€ä¹ˆå‚æ•°çš„ Qwenï¼Ÿ| åŒæ¨¡å‹æ¶æ„ï¼ˆ8B+14Bï¼‰ |\n",
    "| Block 2 | å¦‚ä½•å¤„ç†å¼‚æ„æ•°æ®ï¼Ÿ| æ··åˆRAGï¼ˆBM25+Dense+RRFï¼‰ |\n",
    "| Block 3 | é•¿è¾“å…¥æ€ä¹ˆä¸å‡ºé”™ï¼Ÿ| æ¸è¿›å¼æ€»ç»“+å¢é‡RAG |\n",
    "\n",
    "**æœ€ç»ˆä»·å€¼**: å‚ä¼šè€…æ‹¿èµ°å¯ç›´æ¥ç”¨äºç”Ÿäº§çš„æŠ€æœ¯æ–¹æ¡ˆå’Œä»£ç æ¡†æ¶\n",
    "\n",
    "---\n",
    "\n",
    "### å®æ–½ä¼˜å…ˆçº§\n",
    "\n",
    "1. **ä¼˜å…ˆçº§1**: é€‰å®šæ¨¡å‹è§„æ¨¡ï¼Œå®Œæˆç¡¬ä»¶è¯„ä¼°\n",
    "2. **ä¼˜å…ˆçº§2**: æ­å»ºRAGåŸºç¡€è®¾æ–½ï¼ˆæ··åˆæ£€ç´¢+Rerankingï¼‰\n",
    "3. **ä¼˜å…ˆçº§3**: é›†æˆé•¿è¾“å…¥å¤„ç†é€»è¾‘ï¼ˆæ¸è¿›å¼æ€»ç»“ï¼‰\n",
    "4. **å¯é€‰**: æ ¹æ®å®é™…æ•ˆæœï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦ MoE ç­‰é«˜çº§ä¼˜åŒ–\n",
    "\n",
    "---\n",
    "\n",
    "### é£é™©æ£€æŸ¥æ¸…å•\n",
    "\n",
    "- [ ] æ¨ç†å»¶è¿Ÿæ˜¯å¦ç¨³å®š < 500msï¼Ÿ\n",
    "- [ ] RAG æ£€ç´¢çš„ç²¾åº¦ä¸å¬å›ç‡æ˜¯å¦å¯æ¥å—ï¼Ÿ\n",
    "- [ ] é•¿è¾“å…¥åˆ†æ®µæ˜¯å¦ä¿ç•™äº†å®Œæ•´ä¿¡æ¯ï¼Ÿ\n",
    "- [ ] å¹»è§‰é¢‘ç‡æ˜¯å¦åœ¨å¯æ§èŒƒå›´å†…ï¼Ÿ\n",
    "\n",
    "---\n",
    "\n",
    "### äº’åŠ¨ç¯èŠ‚\n",
    "\n",
    "- å‚ä¼šè€…æå‡ºçš„å…·ä½“åœºæ™¯è®¨è®º\n",
    "- é’ˆå¯¹æ€§çš„æ¨¡å‹é€‰æ‹©å»ºè®®\n",
    "- Q&A æ—¶é—´\n",
    "\n",
    "---\n",
    "\n",
    "## å‚è€ƒèµ„æ–™\n",
    "\n",
    "- **å®éªŒç»“æœè¯¦æƒ…**: [docs/EXPERIMENT3_RESULTS.md](../docs/EXPERIMENT3_RESULTS.md)\n",
    "- **vLLMéƒ¨ç½²æŒ‡å—**: [docs/LOCAL_VLLM_GUIDE.md](../docs/LOCAL_VLLM_GUIDE.md)\n",
    "- **å®Œæ•´ç³»ç»Ÿæ–‡æ¡£**: [README.md](../README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## é™„å½•ï¼švLLM æœåŠ¡ç®¡ç†\n",
    "\n",
    "### æŸ¥çœ‹ vLLM æœåŠ¡æ—¥å¿—\n",
    "\n",
    "å¦‚æœæœåŠ¡å¯åŠ¨å¤±è´¥æˆ–è¿è¡Œå¼‚å¸¸ï¼Œå¯ä»¥æŸ¥çœ‹æ—¥å¿—ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# æŸ¥çœ‹ Qwen3-8B æœ€è¿‘çš„æ—¥å¿—\n",
    "echo \"=== Qwen3-8B (ç«¯å£ 8000) æ—¥å¿— ===\"\n",
    "tail -30 logs/vllm_8b.log\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Qwen3-14B (ç«¯å£ 8001) æ—¥å¿— ===\"\n",
    "tail -30 logs/vllm_14b.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åœæ­¢ vLLM æœåŠ¡\n",
    "\n",
    "Workshop ç»“æŸåï¼Œå¯ä»¥åœæ­¢ vLLM æœåŠ¡é‡Šæ”¾ GPU èµ„æºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# åœæ­¢æ‰€æœ‰vLLMè¿›ç¨‹\n",
    "pkill -f \"vllm.entrypoints.openai.api_server\"\n",
    "echo \"âœ“ vLLM æœåŠ¡å·²åœæ­¢\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
