"""
RAG å·¥å…·åº“
åŒ…å« Embeddingã€å‘é‡ç´¢å¼•ã€Rerankingã€BM25ã€æ··åˆæ£€ç´¢ç­‰æ ¸å¿ƒç»„ä»¶
"""

import os
import time
import math
from typing import List, Dict, Optional, Tuple
from collections import Counter
import numpy as np
import requests
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ‡’åŠ è½½ jiebaï¼ˆé¿å…å¯¼å…¥æ—¶æŠ¥é”™ï¼‰
_jieba = None

def get_jieba():
    """æ‡’åŠ è½½ jieba åˆ†è¯åº“"""
    global _jieba
    if _jieba is None:
        try:
            import jieba
            _jieba = jieba
        except ImportError:
            raise ImportError("è¯·å®‰è£… jieba: uv add jieba")
    return _jieba


class EmbeddingService:
    """åœ¨çº¿ Embedding æœåŠ¡ï¼ˆä½¿ç”¨ BAAI/bge-m3ï¼‰"""

    def __init__(self):
        self.model = os.getenv("EMBEDDING_MODEL", "BAAI/bge-m3")
        self.url = os.getenv("EMBEDDING_URL", "https://api.siliconflow.cn/v1/embeddings")
        self.token = os.getenv("EMBEDDING_TOKEN")
        self.dimension = 1024  # bge-m3 è¾“å‡ºç»´åº¦

        if not self.token:
            raise ValueError("EMBEDDING_TOKEN æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """
        æ‰¹é‡åµŒå…¥æ–‡æœ¬ â†’ å‘é‡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            å‘é‡åˆ—è¡¨ï¼Œæ¯ä¸ªå‘é‡æ˜¯é•¿åº¦ä¸º 1024 çš„æµ®ç‚¹æ•°åˆ—è¡¨
        """
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model,
            "input": texts,
            "encoding_format": "float"
        }

        try:
            response = requests.post(self.url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()
            data = response.json()
            return [item["embedding"] for item in data["data"]]
        except Exception as e:
            raise RuntimeError(f"Embedding API è°ƒç”¨å¤±è´¥: {str(e)}")

    def embed_single(self, text: str) -> np.ndarray:
        """
        åµŒå…¥å•ä¸ªæ–‡æœ¬ â†’ å‘é‡ï¼ˆnumpy æ•°ç»„ï¼‰

        Args:
            text: å•ä¸ªæ–‡æœ¬

        Returns:
            numpy æ•°ç»„å‘é‡
        """
        embeddings = self.embed_texts([text])
        return np.array(embeddings[0])


class VectorIndex:
    """å‘é‡ç´¢å¼•ï¼ˆå­˜å‚¨ä¸æ£€ç´¢ï¼‰"""

    def __init__(self, embedding_service: EmbeddingService):
        self.embedding_service = embedding_service
        self.documents = {}  # doc_id -> {id, title, content}
        self.vectors = {}    # doc_id -> np.array(1024,)

    def add_documents(self, documents: List[Dict]):
        """
        æ‰¹é‡æ·»åŠ æ–‡æ¡£å¹¶ç”Ÿæˆå‘é‡

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å« id, title, content
        """
        if not documents:
            return

        # æå–å†…å®¹ï¼ˆæ ‡é¢˜ + æ­£æ–‡ï¼‰
        contents = [f"{doc['title']} {doc['content']}" for doc in documents]

        # æ‰¹é‡åµŒå…¥
        print(f"ğŸ“Š æ­£åœ¨åµŒå…¥ {len(documents)} ä¸ªæ–‡æ¡£...")
        embeddings = self.embedding_service.embed_texts(contents)

        # å­˜å‚¨
        for doc, embedding in zip(documents, embeddings):
            self.documents[doc["id"]] = doc
            self.vectors[doc["id"]] = np.array(embedding)

        print(f"âœ“ æˆåŠŸç´¢å¼• {len(documents)} ä¸ªæ–‡æ¡£")

    def search(self, query_vector: np.ndarray, top_k: int = 10) -> List[Dict]:
        """
        ç›¸ä¼¼åº¦æ£€ç´¢

        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›å‰ k ä¸ªç»“æœ

        Returns:
            ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœåŒ…å« doc_id, similarity, content
        """
        if not self.vectors:
            return []

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for doc_id, doc_vector in self.vectors.items():
            similarity = float(np.dot(query_vector, doc_vector))
            similarities.append({
                "doc_id": doc_id,
                "similarity": similarity,
                "title": self.documents[doc_id]["title"],
                "content": self.documents[doc_id]["content"]
            })

        # æ’åºå¹¶è¿”å› Top-K
        similarities.sort(key=lambda x: x["similarity"], reverse=True)
        return similarities[:top_k]


class RerankingService:
    """åœ¨çº¿ Reranking æœåŠ¡ï¼ˆä½¿ç”¨ BAAI/bge-reranker-v2-m3ï¼‰"""

    def __init__(self):
        self.model = os.getenv("RERANKING_MODEL", "BAAI/bge-reranker-v2-m3")
        self.url = os.getenv("RERANKING_URL", "https://api.siliconflow.cn/v1/rerank")
        self.token = os.getenv("RERANKING_TOKEN")

        if not self.token:
            raise ValueError("RERANKING_TOKEN æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")

    def rerank(self, query: str, passages: List[Dict], top_k: int = 3) -> List[Dict]:
        """
        ç²¾æ’åº

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            passages: å€™é€‰æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« content å­—æ®µ
            top_k: è¿”å›å‰ k ä¸ªç»“æœ

        Returns:
            é‡æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        if not passages:
            return []

        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model,
            "query": query,
            "documents": [p["content"] for p in passages],
            "top_n": top_k
        }

        try:
            response = requests.post(self.url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()
            data = response.json()

            # è¿”å›é‡æ’åçš„ç»“æœ
            results = []
            for item in data["results"]:
                idx = item["index"]
                passage = passages[idx].copy()
                passage["rerank_score"] = item.get("relevance_score", 0)
                results.append(passage)

            return results

        except Exception as e:
            raise RuntimeError(f"Reranking API è°ƒç”¨å¤±è´¥: {str(e)}")


def retrieve_by_similarity(query: str, index: VectorIndex, embedding_service: EmbeddingService, top_k: int = 10) -> List[Dict]:
    """
    åŸºäºç›¸ä¼¼åº¦çš„æ£€ç´¢

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        index: å‘é‡ç´¢å¼•
        embedding_service: Embedding æœåŠ¡
        top_k: è¿”å›å‰ k ä¸ªç»“æœ

    Returns:
        æ£€ç´¢ç»“æœåˆ—è¡¨
    """
    # åµŒå…¥æŸ¥è¯¢
    query_vector = embedding_service.embed_single(query)

    # æ£€ç´¢
    results = index.search(query_vector, top_k=top_k)

    return results


def rag_retrieve_and_rerank(
    query: str,
    embedding_service: EmbeddingService,
    reranking_service: RerankingService,
    index: VectorIndex,
    retrieval_top_k: int = 10,
    rerank_top_k: int = 3,
    verbose: bool = True
) -> tuple[List[Dict], List[Dict]]:
    """
    å®Œæ•´ RAG æµç¨‹ï¼šæ£€ç´¢ + ç²¾æ’åº

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        embedding_service: Embedding æœåŠ¡
        reranking_service: Reranking æœåŠ¡
        index: å‘é‡ç´¢å¼•
        retrieval_top_k: åˆç­›è¿”å›å‰ k ä¸ª
        rerank_top_k: ç²¾æ’è¿”å›å‰ k ä¸ª
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    Returns:
        (rerank_results, retrieval_results) å…ƒç»„
    """
    if verbose:
        print("\n" + "="*70)
        print(f"ã€RAG æµç¨‹ã€‘æŸ¥è¯¢: {query}")
        print("="*70)

    # æ­¥éª¤ 1ï¼šç›¸ä¼¼åº¦æ£€ç´¢
    if verbose:
        print("\n[æ­¥éª¤ 1] ç›¸ä¼¼åº¦æ£€ç´¢...")

    retrieval_results = retrieve_by_similarity(query, index, embedding_service, top_k=retrieval_top_k)

    if verbose:
        print(f"âœ“ æ£€ç´¢åˆ° {len(retrieval_results)} ä¸ªå€™é€‰æ–‡æ¡£")
        for i, result in enumerate(retrieval_results[:3], 1):
            print(f"  {i}. {result['title']} (ç›¸ä¼¼åº¦: {result['similarity']:.3f})")

    if not retrieval_results:
        return [], []

    # æ­¥éª¤ 2ï¼šReranking ç²¾æ’åº
    if verbose:
        print(f"\n[æ­¥éª¤ 2] Reranking ç²¾æ’åº...")

    rerank_results = reranking_service.rerank(query, retrieval_results, top_k=rerank_top_k)

    if verbose:
        print(f"âœ“ ç²¾æ’å Top {len(rerank_results)} ä¸ªç»“æœï¼š")
        for i, result in enumerate(rerank_results, 1):
            score = result.get('rerank_score', 0)
            print(f"  {i}. {result['title']} (åˆ†æ•°: {score:.3f})")

    return rerank_results, retrieval_results


def build_rag_context(rag_results: List[Dict]) -> str:
    """
    ç»„ç»‡ RAG ä¸Šä¸‹æ–‡

    Args:
        rag_results: RAG æ£€ç´¢ç»“æœ

    Returns:
        æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    """
    if not rag_results:
        return ""

    context_parts = ["ä»¥ä¸‹æ˜¯ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ï¼š\n"]

    for i, result in enumerate(rag_results, 1):
        context_parts.append(f"ã€æ–‡æ¡£ {i}ã€‘{result['title']}")
        context_parts.append(result['content'])
        context_parts.append("")

    context_parts.append("è¯·åŸºäºä»¥ä¸Šå†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚")

    return "\n".join(context_parts)


# ========== å®éªŒ2æ–°å¢ï¼šBM25 æ£€ç´¢ ==========

class BM25:
    """
    BM25 ç®—æ³•å®ç° - æ”¯æŒä¸­æ–‡åˆ†è¯

    ç”¨äºç²¾ç¡®å…³é”®è¯åŒ¹é…ï¼Œè¡¥å…… Dense å‘é‡æ£€ç´¢çš„ä¸è¶³
    """

    def __init__(self, corpus: List[str], k1: float = 1.5, b: float = 0.75):
        """
        åˆå§‹åŒ– BM25 ç´¢å¼•

        Args:
            corpus: æ–‡æ¡£åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰
            k1: è¯é¢‘é¥±å’Œå‚æ•°ï¼ˆé€šå¸¸ 1.2-2.0ï¼‰
            b: é•¿åº¦å½’ä¸€åŒ–å‚æ•°ï¼ˆ0-1ï¼Œ0.75 å¸¸ç”¨ï¼‰
        """
        self.k1 = k1
        self.b = b
        self.corpus = corpus

        jieba = get_jieba()

        # ä½¿ç”¨ jieba è¿›è¡Œä¸­æ–‡åˆ†è¯
        self.corpus_tokens = [list(jieba.cut(doc)) for doc in corpus]
        self.doc_len = [len(tokens) for tokens in self.corpus_tokens]
        self.avgdl = sum(self.doc_len) / len(corpus) if corpus else 0
        self.doc_freqs = []
        self.idf = {}

        # è®¡ç®— IDF (ä½¿ç”¨åˆ†è¯åçš„ token)
        df = Counter()
        for tokens in self.corpus_tokens:
            df.update(set(tokens))

        for term, freq in df.items():
            self.idf[term] = math.log((len(corpus) - freq + 0.5) / (freq + 0.5) + 1)

        # è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„è¯é¢‘
        for tokens in self.corpus_tokens:
            self.doc_freqs.append(Counter(tokens))

    def search(self, query: str, top_k: int = 10) -> List[Tuple[int, float]]:
        """
        æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›å‰ k ä¸ªç»“æœ

        Returns:
            [(doc_idx, score), ...] åˆ—è¡¨
        """
        jieba = get_jieba()

        # æŸ¥è¯¢ä¹Ÿè¿›è¡Œä¸­æ–‡åˆ†è¯
        query_tokens = list(jieba.cut(query))
        scores = []

        for idx, doc_freq in enumerate(self.doc_freqs):
            score = 0
            for term in query_tokens:
                if term not in doc_freq:
                    continue

                freq = doc_freq[term]
                idf = self.idf.get(term, 0)

                # BM25 å…¬å¼
                numerator = freq * (self.k1 + 1)
                denominator = freq + self.k1 * (1 - self.b + self.b * self.doc_len[idx] / self.avgdl)
                score += idf * (numerator / denominator)

            scores.append((idx, score))

        # æ’åºè¿”å› Top-K
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[:top_k]


# ========== å®éªŒ2æ–°å¢ï¼šRRF èåˆç®—æ³• ==========

def rrf_fusion(rankings: List[List[str]], k: int = 60) -> List[Tuple[str, float]]:
    """
    Reciprocal Rank Fusion (RRF) ç®—æ³•

    èåˆå¤šä¸ªæ’åºç»“æœï¼Œå¹³è¡¡ä¸åŒæ£€ç´¢å™¨çš„ä¼˜åŠ¿

    Args:
        rankings: å¤šä¸ªæ’åºç»“æœ [[doc1, doc2, ...], [doc3, doc1, ...]]
        k: å¹³æ»‘å‚æ•°ï¼Œé¿å…å¤´éƒ¨æ–‡æ¡£æƒé‡è¿‡å¤§ï¼ˆé€šå¸¸ 60ï¼‰

    Returns:
        èåˆåçš„æ’åºç»“æœ [(doc_id, score), ...]

    ç¤ºä¾‹:
        >>> rankings = [['doc1', 'doc2'], ['doc2', 'doc3']]
        >>> rrf_fusion(rankings, k=60)
        [('doc2', 0.033), ('doc1', 0.016), ('doc3', 0.016)]
    """
    scores = {}
    for ranking in rankings:
        for rank, doc_id in enumerate(ranking, start=1):
            if doc_id not in scores:
                scores[doc_id] = 0
            scores[doc_id] += 1 / (k + rank)

    return sorted(scores.items(), key=lambda x: x[1], reverse=True)


# ========== å®éªŒ2æ–°å¢ï¼šæ··åˆæ£€ç´¢ ==========

def hybrid_search(
    query: str,
    bm25_index: BM25,
    vector_index: VectorIndex,
    embedding_service: EmbeddingService,
    reranking_service: RerankingService,
    bm25_top_k: int = 20,
    dense_top_k: int = 20,
    rrf_k: int = 60,
    final_top_k: int = 5,
    verbose: bool = True
) -> Tuple[List[Dict], Dict]:
    """
    æ··åˆæ£€ç´¢ä¸»æµç¨‹ï¼ˆBM25 + Dense å‘é‡ + RRF èåˆ + Rerankingï¼‰

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        bm25_index: BM25 ç´¢å¼•
        vector_index: å‘é‡ç´¢å¼•
        embedding_service: Embedding æœåŠ¡
        reranking_service: Reranking æœåŠ¡
        bm25_top_k: BM25 è¿”å›å‰ k ä¸ª
        dense_top_k: Dense å‘é‡è¿”å›å‰ k ä¸ª
        rrf_k: RRF å¹³æ»‘å‚æ•°
        final_top_k: æœ€ç»ˆè¿”å›å‰ k ä¸ª
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    Returns:
        (final_results, debug_info) å…ƒç»„
        - final_results: æœ€ç»ˆ Top-K ç»“æœ
        - debug_info: è°ƒè¯•ä¿¡æ¯ï¼ˆåŒ…å«å„é˜¶æ®µç»“æœå’Œå»¶è¿Ÿï¼‰
    """
    latency = {}

    if verbose:
        print("\n" + "="*70)
        print(f"ã€æ··åˆæ£€ç´¢ã€‘æŸ¥è¯¢: {query}")
        print("="*70)

    # æ­¥éª¤ 1ï¼šBM25 ç¨€ç–æ£€ç´¢
    if verbose:
        print("\n[æ­¥éª¤ 1] BM25 ç¨€ç–æ£€ç´¢...")

    t0 = time.perf_counter()
    bm25_results = bm25_index.search(query, top_k=bm25_top_k)
    latency["bm25_ms"] = (time.perf_counter() - t0) * 1000

    bm25_doc_ids = [str(idx) for idx, score in bm25_results]

    if verbose:
        print(f"âœ“ BM25 æ£€ç´¢è€—æ—¶ {latency['bm25_ms']:.1f}ms")
        print(f"  Top 3: {bm25_doc_ids[:3]}")

    # æ­¥éª¤ 2ï¼šDense å‘é‡æ£€ç´¢
    if verbose:
        print("\n[æ­¥éª¤ 2] Dense å‘é‡æ£€ç´¢...")

    t0 = time.perf_counter()
    query_vector = embedding_service.embed_single(query)
    dense_results = vector_index.search(query_vector, top_k=dense_top_k)
    latency["dense_ms"] = (time.perf_counter() - t0) * 1000

    dense_doc_ids = [r['doc_id'] for r in dense_results]

    if verbose:
        print(f"âœ“ Dense æ£€ç´¢è€—æ—¶ {latency['dense_ms']:.1f}ms")
        print(f"  Top 3: {dense_doc_ids[:3]}")

    # æ­¥éª¤ 3ï¼šRRF èåˆ
    if verbose:
        print("\n[æ­¥éª¤ 3] RRF èåˆ...")

    t0 = time.perf_counter()
    rrf_results = rrf_fusion([bm25_doc_ids, dense_doc_ids], k=rrf_k)
    latency["rrf_ms"] = (time.perf_counter() - t0) * 1000

    if verbose:
        print(f"âœ“ RRF èåˆè€—æ—¶ {latency['rrf_ms']:.1f}ms")
        print(f"  BM25 ä¸ Dense é‡å : {len(set(bm25_doc_ids) & set(dense_doc_ids))} ä¸ª")

    # æ­¥éª¤ 4ï¼šå– Top-40 å€™é€‰æ–‡æ¡£
    t0 = time.perf_counter()
    candidate_doc_ids = [doc_id for doc_id, score in rrf_results[:40]]
    candidate_docs = []

    for doc_id in candidate_doc_ids:
        if doc_id in vector_index.documents:
            doc = vector_index.documents[doc_id].copy()
            doc['rrf_score'] = next((score for did, score in rrf_results if did == doc_id), 0)
            candidate_docs.append(doc)

    latency["candidate_fetch_ms"] = (time.perf_counter() - t0) * 1000

    if verbose:
        print(f"\n[æ­¥éª¤ 4] å‡†å¤‡å€™é€‰æ–‡æ¡£: {len(candidate_docs)} ä¸ª")

    # æ­¥éª¤ 5ï¼šReranking ç²¾æ’
    if verbose:
        print("\n[æ­¥éª¤ 5] Reranking ç²¾æ’...")

    t0 = time.perf_counter()
    final_results = reranking_service.rerank(
        query=query,
        passages=candidate_docs,
        top_k=final_top_k
    )
    latency["rerank_ms"] = (time.perf_counter() - t0) * 1000
    latency["retrieval_total_ms"] = sum(latency.values())

    if verbose:
        print(f"âœ“ Reranking è€—æ—¶ {latency['rerank_ms']:.1f}ms")
        print(f"âœ“ æ€»è€—æ—¶ {latency['retrieval_total_ms']:.1f}ms")
        print(f"\næœ€ç»ˆ Top {len(final_results)} ç»“æœï¼š")
        for i, result in enumerate(final_results, 1):
            score = result.get('rerank_score', 0)
            print(f"  {i}. {result['title']} (Rerankåˆ†æ•°: {score:.3f})")

    # è°ƒè¯•ä¿¡æ¯
    debug_info = {
        "bm25_results": bm25_doc_ids[:5],
        "dense_results": dense_doc_ids[:5],
        "rrf_fused": candidate_doc_ids[:10],
        "final_reranked": [r.get('id', r.get('doc_id', 'unknown')) for r in final_results],
        "overlap_bm25_dense": len(set(bm25_doc_ids) & set(dense_doc_ids)),
        "latency": latency
    }

    return final_results, debug_info

